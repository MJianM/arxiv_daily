---
layout: default
---

## Updated on 2026.02.13

## Categories

- [Manipulation](#manipulation)
- [World Model](#world-model)
- [VLM](#vlm)
- [VLA](#vla)
- [Humanoid](#humanoid)

## Manipulation

| Publish Date | Title | Chinese Summary | Authors | PDF | Code |
|:---------|:-----------------------|:------------------------|:---------|:------|:------|
|**2026-02-12**|**FAIL: Flow Matching Adversarial Imitation Learning for Image Generation**|流匹配模型在后训练中与高质量目标对齐的问题，数学上等同于模仿学习，但现有方法如SFT难以纠正未知状态下的策略漂移，偏好优化成本高。为此，本文提出Flow Matching Adversarial Imitation Learning (FAIL)，通过对抗训练最小化策略与专家之间的差异，且无需显式奖励或成对比较。FAIL包含两种算法：FAIL-PD利用可微分ODE求解器获取低方差路径梯度，FAIL-PG则提供黑盒替代方案。实验表明，仅用13,000个演示数据微调FLUX，FAIL在提示遵循和美学基准上达到了具有竞争力的性能，并能有效泛化至离散图像和视频生成，同时作为鲁棒正则化器缓解奖励欺骗问题。|Weidi Xie Team|[2602.12155](http://arxiv.org/abs/2602.12155)|null|
|**2026-02-12**|**GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning**|现有直接从观测预测多步动作块的视觉-语言-动作（VLA）模型，因场景理解和未来预测能力受限而表现出固有限制。针对此问题，本文提出GigaBrain-0.5M*，一个基于世界模型强化学习（world model-based RL）训练的VLA模型，旨在利用视频世界模型强大的时空推理和预测能力。该模型构建于已在万小时机器人操作数据上预训练的GigaBrain-0.5之上，并通过RAMP（Reinforcement leArning via world Model-conditioned Policy）进一步整合世界模型强化学习，以实现鲁棒的跨任务适应。实验结果表明，RAMP在Laundry Folding、Box Packing、Espresso Preparation等挑战性任务上比RECAP基线性能提升约30%，并且GigaBrain-0.5M*展示了可靠的长周期执行能力，能持续完成复杂操作任务。|Zheng Zhu Team|[2602.12099](http://arxiv.org/abs/2602.12099)|**[link](https://gigabrain05m.github.io/)**|
|**2026-02-12**|**Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning**|在真实世界中直接训练机器人策略成本高昂且难以扩展，而生成式仿真虽能合成大规模数据，却常因开环执行而无法生成逻辑连贯的长周期任务，并难以应对动态物理不确定性。为解决这些挑战，本文提出Affordance-Graphed Task Worlds (AGT-World) 统一框架，该框架能根据真实世界观测自主构建交互式模拟环境和相应的机器人任务策略。AGT-World通过将任务空间形式化为结构化图，实现复杂目标的精确分层分解，并引入结合视觉-语言模型推理和几何验证的混合反馈自进化机制来自主优化策略。广泛实验表明，AGT-World在成功率和泛化能力上显著优于现有方法，实现了提案、执行和纠正的自改进循环，为可扩展的机器人学习提供了有效途径。|Changshui Zhang Team|[2602.12065](http://arxiv.org/abs/2602.12065)|null|
|**2026-02-12**|**HoloBrain-0 Technical Report**|当前基础模型研究与可靠的真实世界机器人部署之间存在差距。为此，本文引入HoloBrain-0，一个全面的视觉-语言-动作（VLA）框架，其核心是融合机器人本体先验（如多视角相机参数和运动学描述URDF）的VLA架构，以增强3D空间推理并支持多样化的机器人本体。该系统采用“预训练-后训练”范式进行验证，并在RoboTwin 2.0、LIBERO和GenieSim等仿真基准以及挑战性的长周期真实世界操作任务中取得了领先或出色的表现。值得注意的是，其高效的0.2B参数版本性能与显著更大的基线模型相当，支持低延迟设备部署。为了加速研究和实际应用，作者完整开源了HoloBrain生态系统，包括强大的预训练VLA基础、用于多个仿真套件和真实世界任务的后训练检查点，以及用于数据整理、模型训练和部署的全栈VLA基础设施RoboOrchard。|Zhizhong Su Team|[2602.12062](http://arxiv.org/abs/2602.12062)|null|
|**2026-02-12**|**When would Vision-Proprioception Policies Fail in Robotic Manipulation?**|本体感知信息对于机器人精确伺服控制至关重要，但视觉-本体策略在泛化性上表现不一致。本文研究发现，在需要目标定位的机器人运动转换子阶段，视觉模态的作用有限，策略在训练过程中自然倾向于能更快降低损失的简洁本体信号，从而抑制了运动转换阶段视觉模态的学习。为缓解此问题，本文提出Gradient Adjustment with Phase-guidance (GAP) 算法，该算法自适应地调节本体感知的优化过程，促进视觉-本体策略的动态协作。具体而言，GAP利用本体感知来估计轨迹中每个时间步属于运动转换阶段的概率，并据此对本体感知的梯度幅度进行精细调整。综合实验证明，GAP适用于仿真和真实世界环境，支持单臂和双臂配置，并兼容传统和视觉-语言-动作模型，有效提升了视觉-本体策略的鲁棒性和泛化能力。|Di Hu Team|[2602.12032](http://arxiv.org/abs/2602.12032)|null|
|**2026-02-12**|**Accelerating Robotic Reinforcement Learning with Agent Guidance**|强化学习在赋予自主机器人掌握通用操作技能方面具有巨大潜力，但在实际应用中因样本效率低下而受阻。尽管现有的人机协作（HIL）方法通过人类纠正加速训练，但其受制于1:1的监督比例、操作员疲劳以及人类技能不一致导致的训练方差大，难以扩展。针对此问题，本文提出Agent-guided Policy Search (AGPS) 框架，通过引入多模态智能体替代人类监督员，实现训练流程的自动化。AGPS的核心思想是将智能体视为语义世界模型，它注入内在价值先验来构造物理探索，并通过可执行工具提供精确的纠正航路点和空间约束以剪枝探索空间。在精确插入和变形物体操作等任务上的验证结果表明，AGPS在样本效率方面优于HIL方法，从而实现了监督流水线的自动化，为无劳动力和可扩展的机器人学习开辟了道路。|Yaodong Yang Team|[2602.11978](http://arxiv.org/abs/2602.11978)|null|
|**2026-02-12**|**Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control**|通用机器人操作的关键瓶颈不仅限于数据规模或策略容量，更在于当前视觉骨干与闭环控制物理需求之间的结构性不匹配：SOTA视觉编码器为分类优化语义不变性，而操作则要求毫米级位姿变化与可预测特征映射的几何敏感性，判别性目标导致精细控制的“盲点”。尽管生成式扩散模型固有地编码了潜在流形中的几何依赖，但直接将其随机特征用于控制存在不稳定、推理延迟和微调时表示漂移等问题。为弥合这一差距，本文提出Robot-DIFT框架，通过流形蒸馏将几何信息来源与推理过程解耦。该方法将冻结的扩散教师模型蒸馏到确定性空间-语义特征金字塔网络（S2-FPN），从而在保留生成模型丰富几何先验的同时，确保时间稳定性、实时执行和抗漂移鲁棒性。在大型Droid数据集上的预训练结果表明，Robot-DIFT在几何一致性和控制性能上优于领先的判别性基线，证明了模型学习“如何看”决定了其“如何行动”的效果。|Georgia Chalvatzaki Team|[2602.11934](http://arxiv.org/abs/2602.11934)|null|
|**2026-02-12**|**JEPA-VLA: Video Predictive Embedding is Needed for VLA Models**|近年来，基于预训练视觉-语言模型（VLMs）构建的视觉-语言-动作（VLA）模型在机器人操作中取得了显著进展，但仍面临样本效率低下和泛化能力有限的挑战。本文认为这些限制与被忽视的预训练视觉表示有关，其在环境理解和策略先验知识方面提供的信息不足。通过深入分析，研究发现VLA中常用的视觉表示（无论是通过语言-图像对比学习还是基于图像的自监督学习预训练）在捕获关键、任务相关的环境信息以及诱导有效策略先验（即对成功任务执行下环境如何演变的预期知识）方面仍然不足。相反，本文发现通过视频预训练的预测嵌入，特别是V-JEPA 2，能够灵活地舍弃不可预测的环境因素并编码任务相关的时态动态，从而有效弥补现有VLA视觉表示的关键缺陷。基于这些观察，本文引入JEPA-VLA，一种简单而有效的方法，自适应地将预测嵌入整合到现有VLA中。实验证明，JEPA-VLA在LIBERO、LIBERO-plus、RoboTwin2.0和真实机器人任务等一系列基准上均取得了显著的性能提升。|Mingsheng Long Team|[2602.11832](http://arxiv.org/abs/2602.11832)|null|
|**2026-02-12**|**Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes**|可靠的3D实例分割是语言驱动机器人操作的基础，但在杂乱环境中，遮挡、有限视角和噪声掩码会严重降低感知性能。为解决这些挑战，本文提出Clutt3R-Seg，一个零样本、鲁棒的3D实例分割流水线，专为杂乱场景中的语言驱动抓取设计。核心思想是引入语义线索的层次实例树，该方法利用噪声掩码作为信息线索，通过跨视图分组和条件替换来抑制过分割和欠分割，从而生成视图一致的掩码和鲁棒的3D实例。每个实例都富含开放词汇语义嵌入，支持从自然语言指令中精确选择目标。此外，为处理多阶段任务中的场景变化，该方法引入了一致性感知更新机制，仅通过一次交互后的单个图像即可保持实例对应关系。Clutt3R-Seg在合成和真实世界数据集及真实机器人上均表现出色，在杂乱和稀疏视图场景中持续优于SOTA基线，在重度杂乱序列中AP@25达到61.66，比基线高2.2倍以上。|Ayoung Kim Team|[2602.11660](http://arxiv.org/abs/2602.11660)|null|
|**2026-02-12**|**ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning**|触觉信息在机器人操作中日益受到关注，但现有方法大多侧重于视觉与触觉特征的对齐，且集成机制常为直接拼接，导致在遮挡场景下表现不佳，未能充分利用两种模态固有的互补性，从而限制了实际部署潜力。为此，本文提出ViTaS，一个简单而有效的框架，结合视觉和触觉信息来指导智能体的行为。该框架引入了Soft Fusion对比学习（一种改进的对比学习方法）和一个CVAE模块，以利用视触觉表示中的对齐性和互补性。实验结果表明，ViTaS在12个仿真环境和3个真实世界环境中均表现出显著优于现有基线的性能，证明了其有效性。|Huazhe Xu Team|[2602.11643](http://arxiv.org/abs/2602.11643)|null|
|**2026-02-12**|**EasyMimic: A Low-Cost Framework for Robot Imitation Learning from Human Videos**|针对机器人模仿学习中真实世界数据收集成本高昂的问题，尤其是在低成本家用机器人领域，本研究提出了EasyMimic框架。该方法通过标准RGB相机捕获人类视频，提取3D手部轨迹，并利用动作对齐模块映射到机器人夹持器控制空间。为弥合人-机域鸿沟，引入了手部视觉增强策略，并结合协同训练在处理后的人类数据和少量机器人数据上快速适应新任务。实验表明，EasyMimic在LeRobot平台上实现了高效的操作性能，显著降低了对昂贵机器人数据的依赖。|Qin Jin Team|[2602.11464](http://arxiv.org/abs/2602.11464)|null|
|**2026-02-12**|**Scaling World Model for Hierarchical Manipulation Policies**|视觉-语言-动作（VLA）模型在通用机器人操作中面临域外泛化能力不足的挑战。本研究提出了VISTA分层框架，利用大规模预训练世界模型的泛化能力实现鲁棒且可泛化的视觉子目标任务分解。该框架将世界模型作为高层规划器，负责将操作任务分解为带有目标图像的子任务序列，而低层VLA策略则依据文本和视觉指导生成动作。实验结果显示，通过世界模型生成的视觉目标指导，相同结构的VLA在域外场景中的性能显著提升，验证了其在未见物体和新场景下的强大泛化能力。|Xinghang Li Team|[2602.10983](http://arxiv.org/abs/2602.10983)|null|
|**2026-02-11**|**Human Preference Modeling Using Visual Motion Prediction Improves Robot Skill Learning from Egocentric Human Video**|现有从第一视角人类视频中学习机器人奖励函数的方法存在假设限制和跨域迁移挑战。本研究提出一种新方法，通过预测图像中跟踪点的运动来建模人类偏好，并定义奖励函数为每一步预测与观察到的物体运动的一致性。随后，利用修改后的Soft Actor Critic (SAC) 算法，在少量真实机器人演示的初始化下，直接在机器人上估计值函数并优化策略。实验证明，该奖励模型学习的策略在仿真和真实机器人的多个任务中均达到或超越了现有性能。|Christopher G. Atkeson Team|[2602.11393](http://arxiv.org/abs/2602.11393)|null|
|**2026-02-11**|**MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation**|机器人大规模部署面临长尾场景和环境多样性的挑战，而现有基准测试缺乏所需规模。本研究推出了MolmoSpaces生态系统，包含超过23万个多样化室内环境和13万个丰富标注的物体资产，且与模拟器无关，支持各类具身任务。MolmoSpaces-Bench基准套件包含8个任务，用于评估机器人与多样化场景的交互。实验结果显示，该基准测试具有高模拟到现实相关性，并成功识别了新零样本策略的优越性以及对关键参数的敏感性，为可扩展的数据生成和策略训练提供了基础。|Ranjay Krishna Team|[2602.11337](http://arxiv.org/abs/2602.11337)|null|
|**2026-02-11**|**YOR: Your Own Mobile Manipulator for Generalizable Robotics**|鉴于低成本机器人平台日益增长的需求，本研究旨在探索移动操作器的最佳形式。本文介绍了YOR，一款开源、低成本的移动操纵器，其设计强调模块化、易于组装和经济性（物料清单成本低于1万美元）。YOR集成了全向底座、伸缩式升降装置和双臂夹持器，实现了全身移动和操作。实验证明，YOR能够完成需要协调全身控制、双手操作和自主导航的任务，以远低于现有平台的成本提供了有竞争力的移动操作功能。|Zichen Jeff Cui Team|[2602.11150](http://arxiv.org/abs/2602.11150)|null|
|**2026-02-11**|**ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning**|为解决跨多样化硬件构建通用具身智能体面临的数据碎片化和表示不一致问题，本研究提出了ABot-M0框架。该框架通过系统化的数据整理流程和模型架构、训练策略的联合优化，将异构原始数据转换为统一高效的表示，并构建了UniACT-dataset大规模数据集。基于动作流形假设，引入Action Manifold Learning (AML) 直接预测连续动作序列，提高解码效率和策略稳定性。通过双流机制实现模块化感知，整合VLM语义与几何先验和多视图输入。实验证明各组件独立运行并带来累加效益，支持通用具身智能体的泛化和知识迁移。|Mu Xu Team|[2602.11236](http://arxiv.org/abs/2602.11236)|**[link](https://amap-cvlab.github.io/ABot-Manipulation/)**|
|**2026-02-11**|**OSIL: Learning Offline Safe Imitation Policies with Safety Inferred from Non-preferred Trajectories**|针对离线安全模仿学习中缺乏每一步安全成本或奖励信息的问题，本研究提出了OSIL算法。OSIL通过从“非偏好轨迹”中推断安全性，并将其表述为约束马尔可夫决策过程 (CMDP)。该方法通过推导奖励最大化目标的下界和学习成本模型来估计非偏好行为的可能性，从而无需显式安全成本或奖励标注。实验证明，OSIL能够在不损害奖励性能的情况下，完全从离线演示中学习出满足成本约束且更安全的策略，优于现有基线方法。|Balaraman Ravindran Team|[2602.11018](http://arxiv.org/abs/2602.11018)|null|
|**2026-02-11**|**Towards Learning a Generalizable 3D Scene Representation from 2D Observations**|为了解决传统方法在相机中心坐标系中操作难以直接应用于机器人操纵的问题，本研究提出了一种可泛化的神经辐射场方法。该模型旨在从机器人第一视角观测中预测3D工作空间占用，并在全局工作空间框架中构建占用表示。该方法能够集成灵活的源视图，并泛化到未见对象布置而无需进行场景特定微调。在人形机器人上的实验结果表明，该模型在40个真实场景训练后，实现了26毫米的重建误差（包括遮挡区域），验证了其超越传统立体视觉方法推断完整3D占用信息的能力。|Stefan Wermter Team|[2602.10943](http://arxiv.org/abs/2602.10943)|null|
|**2026-02-11**|**Semi-Supervised Cross-Domain Imitation Learning**|跨域模仿学习（CDIL）在专家数据收集昂贵时具有重要价值，但现有方法或依赖监督对齐，或无监督但不稳定。本研究引入了半监督CDIL（SS-CDIL）设置，并提出了首个具有理论依据的算法。该方法仅利用离线数据，包括少量目标专家演示和一些未标注的不完美轨迹。为处理域差异，该方法设计了新颖的跨域损失函数学习域间状态-动作映射，并引入自适应权重函数平衡源域和目标域知识。实验表明，该方法在最小监督下实现了稳定且数据高效的策略学习，性能优于现有基线。|Ping-Chun Hsieh Team|[2602.10793](http://arxiv.org/abs/2602.10793)|null|
|**2026-02-11**|**Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation**|机器人操作中，现有系统普遍缺乏预测环境响应的能力，导致效率低下。针对视觉-语言模型无法显式预测未来状态以及现有世界模型预测范围有限或空间不一致的问题，本研究提出了一个快速预测视频条件动作的框架。该方法首先选择并调整鲁棒视频生成模型以确保可靠预测，然后应用对抗蒸馏实现快速少量步骤的视频生成，最后训练一个动作模型，利用生成视频和真实观测纠正空间误差。广泛实验表明，该方法生成了时间连贯、空间准确的视频预测，显著提升了具身一致性、空间指代能力和任务完成度。|Yanwei Fu Team|[2602.10717](http://arxiv.org/abs/2602.10717)|null|

<p align=right>(<a href=#updated-on-20260213>back to top</a>)</p>

## World Model

| Publish Date | Title | Chinese Summary | Authors | PDF | Code |
|:---------|:-----------------------|:------------------------|:---------|:------|:------|
|**2026-02-12**|**The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics**|在评估神经网络模型是否真正内化物理定律而非利用统计捷径时，特别是在分布外（OOD）测试下，现有方法存在挑战，因为下游适应性评估会改变表征，混淆模型的学习内容。本文提出了非侵入式评估协议PhyIP，通过检测物理量是否可从冻结的表征中线性解码来验证物理世界模型。实验结果表明，在流体动力学和轨道力学任务中，当自监督学习（SSL）误差较低时，潜在结构变得线性可访问，PhyIP在OOD测试上成功恢复了内能和牛顿平方反比律（ρ>0.90），而基于适应性的评估则可能掩盖这些结构（ρ≈0.05）。这表明低容量探测器能更准确地评估物理世界模型。|Barbara Hammer Team|[2602.12218](http://arxiv.org/abs/2602.12218)|null|
|**2026-02-12**|**LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion**|当前机器人基础模型多依赖行为克隆，忽略了异构具身数据中蕴含的可迁移动力学知识，而统一世界模型（UWM）因数据使用粗糙和数据集碎片化难以扩展。本文提出了LDA-1B，一个通过通用具身数据摄取进行扩展的机器人基础模型，它联合学习动力学、策略和视觉预测，并为不同质量的数据分配不同角色。为支持大规模学习，研究构建了EI-30k数据集，并利用DINO潜在空间进行结构化预测以避免像素级建模。LDA-1B采用多模态扩散Transformer处理异步视觉和动作流，实现了10亿参数规模的稳定训练。实验证明，LDA-1B在接触密集、灵巧和长时序任务上分别比现有方法（如π0.5）性能提升高达21%、48%和23%，并能有效利用低质量轨迹进行数据高效微调，性能提升10%。|He Wang Team|[2602.12215](http://arxiv.org/abs/2602.12215)|**[link](https://pku-epic.github.io/LDA)**|
|**2026-02-12**|**DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation**|现有音视频生成模型将以人为中心的任务（如参考音视频生成、视频编辑、音频驱动视频动画）视为孤立目标，且难以在单一框架内实现对多角色身份和音色的精确解耦控制。本文提出了DreamID-Omni，一个可控的以人为中心音视频生成统一框架。该框架设计了一个对称条件扩散Transformer，通过对称条件注入方案整合异构条件信号，并引入了双层解耦策略（信号级的同步RoPE和语义级的结构化字幕）以解决身份-音色绑定失败和说话人混淆问题。此外，还设计了多任务渐进式训练方案，利用弱约束生成先验来规范强约束任务。广泛实验表明，DreamID-Omni在视频、音频和视听一致性方面取得了全面领先的SOTA表现，甚至超越了顶级的商业模型。|Xiangwang Hou Team|[2602.12160](http://arxiv.org/abs/2602.12160)|**[link](https://guoxu1233.github.io/DreamID-Omni/)**|
|**2026-02-12**|**It's TIME: Towards the Next Generation of Time Series Forecasting Benchmarks**|现有时间序列基础模型（TSFM）基准在数据构成、数据完整性、任务制定和分析视角上存在局限。为解决这些问题，本文引入了TIME，一个新一代以任务为中心的基准，包含50个全新数据集和98个预测任务，专为严格的零样本TSFM评估设计，避免数据泄露。研究整合了大型语言模型和人类专业知识，建立了严谨的人机协作基准构建流程，以确保数据完整性，并通过将预测配置与实际操作需求和变量可预测性对齐来重新定义任务制定。此外，提出了新颖的模式级评估视角，超越传统数据集级评估，通过利用结构化时间序列特征表征内在时间属性，为模型在不同模式下的能力提供通用洞察。实验评估了12个代表性TSFM并建立了多粒度排行榜以促进深入分析。|Chenghao Liu Team|[2602.12147](http://arxiv.org/abs/2602.12147)|null|
|**2026-02-12**|**Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models**|许多大学面临日益增长的财政压力，并依赖对入学人数的准确预测，但高等教育中的入学预测通常数据稀疏，且年度序列短，易受报告变化和制度转变影响，导致经典方法不可靠。本文在零样本设置下，基准测试了多种时间序列基础模型（TSFM）家族，并测试了一组紧凑、防泄露的协变量集。研究引入了“机构运营条件指数”（IOCI），一个可转移的0-100区间制度协变量，以及结合稳定特征工程的Google趋势需求代理。通过严格的时间窗口扩展回溯测试，结果显示，在不进行机构特定训练的情况下，条件协变量的TSFMs表现与经典基准相当，性能差异因队列和模型而异。|Surangika Ranathunga Team|[2602.12120](http://arxiv.org/abs/2602.12120)|null|
|**2026-02-12**|**The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context**|当前AI模型，特别是大型语言模型（LLMs），缺乏主动管理自身记忆的能力，仅被动接受手动设计的上下文，受限于固定窗口的架构。本文提出了StateLM，一类新型基础模型，其核心是赋予模型内部推理循环以管理自身状态的能力。我们为模型配备了一套记忆工具，包括上下文剪枝、文档索引和笔记功能，并训练其主动管理这些工具，从而动态构建自己的上下文。实验证明，StateLM在所有模型规模的长文档问答任务上始终优于标准LLMs；在聊天记忆任务上，绝对准确率提升了10%到20%；在深度研究任务BrowseComp-Plus上，StateLM准确率高达52%，而标准LLMs仅为5%左右。该方法将LLMs从被动预测器转变为具备状态感知的智能体，使推理成为一个有状态且可管理的过程。|Yan Wang Team|[2602.12108](http://arxiv.org/abs/2602.12108)|null|
|**2026-02-12**|**GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning**|直接预测多步动作块的视觉-语言-动作（VLA）模型受限于场景理解和未来预测能力。本文提出GigaBrain-0.5M*，一个基于世界模型强化学习训练的VLA模型，旨在利用预训练于海量视频语料库的世界模型强大的时空推理和预测能力。该模型以在超过10000小时机器人操作数据上预训练的GigaBrain-0.5为基础，并通过RAMP（Reinforcement leArning via world Model-conditioned Policy）进一步整合世界模型强化学习，以实现强大的跨任务适应性。实验结果表明，RAMP在Laundry Folding、Box Packing和Espresso Preparation等挑战性任务上比RECAP基线提高了约30%。GigaBrain-0.5M*展现了可靠的长时序执行能力，在实际部署中能持续无故障地完成复杂操作任务。|Zheng Zhu Team|[2602.12099](http://arxiv.org/abs/2602.12099)|**[link](https://gigabrain05m.github.io/)**|
|**2026-02-12**|**Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning**|在真实世界中训练机器人策略成本高昂且难以扩展，而生成式仿真虽能合成大量数据，但现有方法难以生成逻辑连贯的长时序任务，且因开环执行而难以处理动态物理不确定性。为解决这些挑战，本文提出了Affordance-Graphed Task Worlds (AGT-World)，一个统一框架，可根据真实世界观察自主构建交互式仿真环境及相应的机器人任务策略。AGT-World将任务空间形式化为结构化图，实现复杂目标的精确分层分解。此外，引入了混合反馈的自进化机制（结合视觉-语言模型推理和几何验证）来自主优化策略。广泛实验表明，该方法在成功率和泛化能力上显著优于现有方法，实现了提案、执行和修正的自改进循环，以实现可扩展的机器人学习。|Changshui Zhang Team|[2602.12065](http://arxiv.org/abs/2602.12065)|null|
|**2026-02-12**|**VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model**|通过迭代在线交互提升视觉-语言-动作（VLA）模型性能和可靠性在真实世界中成本高昂。尽管学习型模拟器（动作条件视频生成模型）可用于生成额外训练数据，但现有世界模型缺乏物理保真度，特别是在许多物理交互（尤其是失败情况）的覆盖以及接触密集物体操作中微小而关键的物理细节建模方面表现不足。本文提出了一种简单的迭代改进算法，该算法利用真实世界的数据来提高世界模型的保真度，然后将改进后的世界模型用于生成补充合成数据以进一步提升VLA模型。在真实机器人上的实验表明，此方法使一个先进的VLA模型在多个下游任务上的成功率比基础策略绝对提升了39.2%，其中11.6%的提升来源于使用生成的合成数据进行训练。|Chelsea Finn Team|[2602.12063](http://arxiv.org/abs/2602.12063)|null|
|**2026-02-12**|**HoloBrain-0 Technical Report**|现有基础模型研究与可靠的真实世界机器人部署之间的差距仍然存在，尤其在视觉-语言-动作（VLA）模型中，机器人具身先验的融入不足。本文提出了HoloBrain-0，一个全面的VLA框架，其核心是一个新颖的VLA架构，明确融入了机器人具身先验（包括多视角相机参数和运动学描述URDF），以增强3D空间推理并支持多样化的具身平台。通过可扩展的“预训练-后训练”范式，该设计在RoboTwin 2.0、LIBERO和GenieSim等仿真基准上实现了最先进的结果，并在具有挑战性的长时序真实世界操作任务中表现出色。值得注意的是，其高效的0.2B参数变体能与更大的基线模型相媲美，实现低延迟的设备端部署。为了进一步加速研究和实际应用，HoloBrain生态系统已完全开源，包括强大的预训练VLA基础模型、多个仿真套件和真实世界任务的后训练检查点，以及用于数据整理、模型训练和部署的全栈VLA基础设施RoboOrchard。结合标准化的数据收集协议，这一发布为社区提供了实现高性能机器人操作的完整、可复现路径。|Zhizhong Su Team|[2602.12062](http://arxiv.org/abs/2602.12062)|null|
|**2026-02-12**|**FedGRPO: Privately Optimizing Foundation Models with Group-Relative Rewards from Domain Client**|针对联邦基础模型(FedFMs)中现有知识迁移方法存在的昂贵训练、高通信成本和隐私风险问题，本研究提出FedGRPO框架。该框架将问题重新定义为强化学习评估，通过构建轻量级置信图进行基于能力的专家选择，并利用"Group Relative"概念将问题与解决方案打包为候选策略，仅聚合选定客户端的标量奖励信号。实验证明，FedGRPO通过交换奖励值而非数据或模型更新，有效降低了隐私风险和通信开销，并在下游任务中实现了卓越的准确性和通信效率。|Yuxing Han Team|[2602.12014](http://arxiv.org/abs/2602.12014)|null|
|**2026-02-12**|**Accelerating Robotic Reinforcement Learning with Agent Guidance**|强化学习在机器人通用操作技能习得上面临样本效率低和人机交互(HIL)方法可扩展性受限的挑战。本研究提出Agent-guided Policy Search (AGPS)框架，通过多模态智能体取代人类监督员，实现训练过程自动化。AGPS将智能体视为语义世界模型，利用可执行工具提供精确的校正路径点和空间约束来指导探索。实验结果表明，AGPS在样本效率方面优于HIL方法，为实现无需人工、可扩展的机器人学习提供了新途径。|Yaodong Yang Team|[2602.11978](http://arxiv.org/abs/2602.11978)|null|
|**2026-02-12**|**Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning**|为实现高效空间推理，本研究探讨了世界模型在低位宽预算下规划行为的影响，特别是位宽总数与模块间分配的相对重要性。通过在DINO-WM上进行Wall规划任务的混合位评估，发现存在8/6位接近FP16、3位崩溃、4位对分配敏感的三区域模式。在4位转换区，保留编码器精度可提升规划性能。这些结果表明，高效空间推理需引入模块感知和预算感知的量化策略。|Vaishak Menon Team|[2602.11882](http://arxiv.org/abs/2602.11882)|null|
|**2026-02-12**|**PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts**|鉴于潜在扩散模型(LDMs)在 <=0.25°高分辨率集合天气预报中扩散性受限，且现有方法无法有效处理多变量气象数据中的光谱异质性问题，本研究提出PuYun-LDM。该模型结合3D Masked AutoEncoder编码天气状态演化特征作为额外条件，以及Variable-Aware Masked Frequency Modeling策略自适应选择阈值。实验结果显示，PuYun-LDM增强了潜在扩散性，在短时效内预测性能优于ENS，长时效内与之相当，并能在短时间内高效生成全球预报。|Bin Wang Team|[2602.11807](http://arxiv.org/abs/2602.11807)|null|
|**2026-02-12**|**HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model**|针对类人机器人在非结构化环境中与具有独立动力学和非完整约束的欠驱动物体交互时的挑战，本研究提出HAIC框架。该框架通过一个动力学预测器，仅利用本体感受历史估计物体高阶状态，并将其投射到静态几何先验上形成动态占用图，从而使策略能在盲区推断碰撞和接触可供性。通过不对称微调，世界模型持续适应学生策略。实验表明，HAIC在敏捷任务和多物体长时任务中实现了高成功率，展现出对惯性扰动的主动补偿能力。|Renjing Xu Team|[2602.11758](http://arxiv.org/abs/2602.11758)|**[link](https://haic-humanoid.github.io/)**|
|**2026-02-12**|**ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation**|为解决具身导航领域任务架构碎片化问题，本研究引入了ABot-N0，一个统一的视觉-语言-动作(VLA)基础模型。ABot-N0采用分层“大脑-行动”架构，结合基于LLM的认知大脑进行语义推理与基于流匹配的行动专家进行精确轨迹生成，并构建了大规模数据引擎。ABot-N0在5个核心任务上实现了“大一统”，并在7个基准测试中取得新的SOTA性能，显著优于专用模型。其集成的Agentic导航系统通过分层拓扑记忆，进一步支持了真实世界中鲁棒、长时程任务。|Mu Xu Team|[2602.11598](http://arxiv.org/abs/2602.11598)|**[link](https://amap-cvlab.github.io/ABot-Navigation/ABot-N0/)**|
|**2026-02-12**|**Brain4FMs: A Benchmark of Foundation Models for Electrical Brain Signal**|脑基础模型(BFMs)正推动神经科学发展，但缺乏统一方法论和标准化评估框架。为填补此空白，本研究绘制了BFM的基准设计空间，从模型角度基于自监督学习(SSL)分类法组织BFMs，并从数据集角度总结下游任务和整理公开数据集。在此基础上，开发了Brain4FMs开放评估平台，集成了15个BFMs和18个数据集，实现了标准化比较和分析预训练数据、SSL策略和架构对泛化性能的影响，以指导更准确、可迁移BFMs的开发。|Yang Yang Team|[2602.11558](http://arxiv.org/abs/2602.11558)|null|
|**2026-02-12**|**TS-Memory: Plug-and-Play Memory for Time Series Foundation Models**|时间序列基础模型(TSFMs)在零样本预测方面表现出色，但在分布偏移下适应下游领域时面临挑战。本研究提出Parametric Memory Distillation方法，并实现为TS-Memory，一个轻量级记忆适配器以增强冻结的TSFMs。TS-Memory分两阶段训练：首先构建离线kNN教师合成置信度感知的量化目标，其次通过置信度门控监督将其蒸馏到记忆适配器中。实验证明，TS-Memory在点预测和概率预测方面持续优于现有适应方法，且推理效率与冻结骨干网络相当。|Yuxuan Liang Team|[2602.11550](http://arxiv.org/abs/2602.11550)|null|
|**2026-02-12**|**Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use**|针对预算受限的工具增强型智能体在解决多步骤任务时，因工具执行的定价与随机性导致直接规划不可行的问题，本研究提出INTENT框架。INTENT是一种推理时规划方法，它利用意图感知分层世界模型来预测未来的工具使用、风险校准成本，并在线指导决策。在成本增强型StableToolBench上的实验表明，INTENT严格遵循预算可行性，显著提高了任务成功率，并在动态市场变化下保持了鲁棒性。|Qi Qi Team|[2602.11541](http://arxiv.org/abs/2602.11541)|null|
|**2026-02-12**|**Vascular anatomy-aware self-supervised pre-training for X-ray angiogram analysis**|X射线血管造影在心血管疾病诊断中受限于注释数据稀缺和缺乏有效自监督学习(SSL)框架。本研究提出VasoMIM血管解剖结构感知掩码图像建模框架，通过解剖结构引导的掩码策略强制模型学习血管语义，并利用解剖结构一致性损失增强表示的判别力。同时，构建了目前最大的X射线血管造影预训练数据集XA-170K。实验表明，VasoMIM在多个下游任务上展现出优越的可迁移性和SOTA性能，凸显了其作为X射线血管造影分析基础模型的巨大潜力。|Zeng-Guang Hou Team|[2602.11536](http://arxiv.org/abs/2602.11536)|null|

<p align=right>(<a href=#updated-on-20260213>back to top</a>)</p>

## VLM

| Publish Date | Title | Chinese Summary | Authors | PDF | Code |
|:---------|:-----------------------|:------------------------|:---------|:------|:------|
|**2026-02-12**|**Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment**|现有视觉-语言-动作（VLA）模型在执行自然语言指令时常出现行动与意图不符的问题。为此，本研究提出一种测试时验证方法来缩小这一“意图-行动”差距。该方法通过联合扩展复述指令数量和生成动作候选来增加测试时样本多样性，并引入CoVer（一种视觉-语言-动作对齐的对比验证器）及分层验证推理流程，利用VLM预计算指令，生成动作候选，并由验证器选出最优方案。实验结果表明，该验证方法在SIMPLER基准上实现了分布内22%和分布外13%的性能提升，在真实世界实验中提升了45%，在PolaRiS基准上任务进度提高了14%，成功率提高了9%。|Marco Pavone Team|[2602.12281](http://arxiv.org/abs/2602.12281)|null|
|**2026-02-12**|**ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images**|通用视觉语言模型（VLMs）在文档理解方面表现出色，但其在多种文档类型和灵活模式下进行全面、细粒度结构化信息提取的能力尚待充分研究。为弥补现有关键实体提取、关系提取和视觉问答数据集的局限性，本研究引入了ExStrucTiny，一个用于从文档图像中进行结构化信息提取的新基准数据集。该数据集通过结合人工和合成样本的新颖流程构建，涵盖了更多样化的文档类型和提取场景。对开源和闭源VLM在该基准上的分析揭示了模式适应、查询欠规范和答案定位等挑战，为未来通用模型在文档结构化信息提取方面的改进奠定了基础。|Manuela Veloso Team|[2602.12203](http://arxiv.org/abs/2602.12203)|null|
|**2026-02-12**|**3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting**|现有零样本物体导航（ZSON）方法依赖于将环境抽象为语义地图或文本表示，导致高级决策受限于低级感知的准确性。本研究提出3DGSNav，一个新颖的ZSON框架，将3D高斯辐射场（3DGS）作为VLM的持久记忆，以增强空间推理能力。该方法通过主动感知逐步构建环境的3DGS表示，实现轨迹引导的自由视点渲染，并结合结构化视觉提示和思维链（CoT）提示来改进VLM的推理。在导航过程中，实时物体检测器过滤潜在目标，并通过VLM驱动的主动视点切换进行目标再验证。大量基准测试和真实世界四足机器人实验证明，该方法在鲁棒性和性能上均优于现有先进方法。|Xinyi Yu Team|[2602.12159](http://arxiv.org/abs/2602.12159)|null|
|**2026-02-12**|**Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning**|在真实世界中训练机器人策略成本高昂且难以扩展。尽管生成式仿真能合成大规模数据，但现有方法常难以生成逻辑连贯的长期任务，且因开环执行而难以应对动态物理不确定性。为解决这些挑战，本研究提出了Affordance-Graphed Task Worlds (AGT-World)，一个统一的框架，能基于真实世界观察自主构建交互式仿真环境和相应的机器人任务策略。该框架将任务空间形式化为结构化图，实现复杂目标的精确分层分解，并引入了结合视觉语言模型推理和几何验证的混合反馈“自演化”机制来自主优化策略。实验结果表明，该方法在成功率和泛化性方面显著优于现有方法，实现了可扩展机器人学习的提出、执行和纠正的自改进循环。|Changshui Zhang Team|[2602.12065](http://arxiv.org/abs/2602.12065)|null|
|**2026-02-12**|**Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation**|新生儿复苏的准确记录对于质量改进至关重要，但在实践中利用率不足，现有3D-CNN和ViT方法在识别精细活动时面临挑战。本研究旨在探索生成式AI（GenAI）方法，特别是结合大型语言模型（LLM）的局部视觉语言模型（VLM）在改进新生儿复苏视频活动识别方面的潜力，并与监督式TimeSFormer基线进行比较。利用一个包含13.26小时模拟视频的数据集，评估了多种零样本VLM策略和经过LoRA微调的VLM。结果显示，小型VLM虽然存在幻觉问题，但经过LoRA微调后，其F1分数达到0.91，显著超越了TimeSFormer的0.70分。|Øyvind Meinich-Bache Team|[2602.12002](http://arxiv.org/abs/2602.12002)|null|
|**2026-02-12**|**Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion**|PDF到Markdown的转换是检索增强生成（RAG）流程的关键步骤，但转录和布局错误会影响后续检索和推理。现有基准多侧重于英语或中文，且常对下游应用无害的格式差异过度惩罚。为此，本研究提出了一个专注于法语的、针对性强的困难文档基准，通过模型分歧采样从6万份文档中选取，涵盖手写表单、复杂布局、密集表格和图文并茂页面。评估采用针对具体故障模式（文本存在、阅读顺序、局部表格约束）的单元测试式检查，并结合类别特定的归一化处理。对15个模型的评估显示，在手写和表单方面，最强的专有模型表现出显著更高的鲁棒性，而一些开源模型在标准打印布局上仍具竞争力。|Nicolas Mery Team|[2602.11960](http://arxiv.org/abs/2602.11960)|null|
|**2026-02-12**|**Are Two LLMs Better Than One? A Student-Teacher Dual-Head LLMs Architecture for Pharmaceutical Content Optimization**|大型语言模型（LLMs）在制药等受监管领域的内容创作中应用日益广泛，但其输出必须科学准确且符合法规。人工质量控制（QC）效率低下且易出错。本研究引入了LRBTC，一个模块化的LLM和VLM驱动的质量控制架构，涵盖语言、法规、品牌、技术和内容结构检查。该架构结合了学生-教师双模型体系和人机协作工作流，通过瀑布规则过滤，实现了可扩展、可验证的内容验证和优化。在AIReg-Bench上的实验结果显示，LRBTC取得了83.0%的F1分数和97.5%的召回率，将未发现的违规行为减少了5倍。在CSpelling上，平均准确率提高了26.7%。误差分析表明，模型擅长检测拼写错误（92.5%召回率），但未能识别复杂的医学语法（25.0%召回率）和标点符号错误（41.7%召回率），揭示了未来研究的关键领域。|Anubhav Girdhar Team|[2602.11957](http://arxiv.org/abs/2602.11957)|null|
|**2026-02-12**|**LAMP: Implicit Language Map for Robot Navigation**|现有零样本导航方法通过在栅格或基于节点的地图中明确存储语言向量，在大规模环境中面临内存需求过高和分辨率有限的问题，阻碍了细粒度规划。本研究提出了LAMP（语言地图），一种新颖的基于神经语言场的导航框架。该框架将语言特征编码为隐式神经场，学习一个连续的、语言驱动的地图，并利用其进行细粒度路径生成。通过结合隐式表示和稀疏图进行高效粗粒度路径规划，并通过学习到的场进行基于梯度的优化以精确定位目标附近位姿。为增强鲁棒性，该方法采用贝叶斯框架对嵌入不确定性进行建模，并通过图采样策略提升在大环境中的可扩展性。在NVIDIA Isaac Sim和真实多层建筑中的实验结果表明，LAMP在内存效率和细粒度目标到达精度上均优于现有显式方法。|Sunwook Choi Team|[2602.11862](http://arxiv.org/abs/2602.11862)|**[link](https://lab-of-ai-and-robotics.github.io/LAMP/)**|
|**2026-02-12**|**JEPA-VLA: Video Predictive Embedding is Needed for VLA Models**|当前视觉-语言-动作（VLA）模型在机器人操作中样本效率低、泛化能力有限，这很大程度上源于预训练视觉表征在环境理解和策略先验方面知识不足。本研究通过深入分析发现，现有的视觉表征无法有效捕捉任务相关的环境信息和诱导有效的策略先验。相反，经视频预训练的预测性嵌入（特别是V-JEPA 2）能灵活地摒弃不可预测的环境因素并编码任务相关的时态动态，有效弥补了现有视觉表征的关键缺陷。基于这些观察，本研究提出了JEPA-VLA，一种简单而有效的方法，将预测性嵌入自适应地整合到现有VLA模型中。实验证明，JEPA-VLA在LIBERO、LIBERO-plus、RoboTwin2.0和真实机器人任务等一系列基准测试中均取得了显著的性能提升。|Mingsheng Long Team|[2602.11832](http://arxiv.org/abs/2602.11832)|null|
|**2026-02-12**|**Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models**|尽管大型视觉-语言模型（LVLMs）能力先进，但常出现物体幻觉问题，原因在于视觉特征和预训练文本表示在深层网络中相互纠缠，抑制了视觉信息。本研究提出了一种免训练框架REVIS，旨在明确地重新激活被抑制的视觉信息。该方法基于潜在空间几何原理，通过正交投影提取纯视觉信息向量，并采用校准策略，仅在发生抑制的精确深度进行稀疏干预。实验评估表明，REVIS将物体幻觉率相比现有最佳基线降低了约19%，同时保留了通用的推理能力。|Zhou Yang Team|[2602.11824](http://arxiv.org/abs/2602.11824)|null|
|**2026-02-12**|**Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation**|针对视觉-语言模型（如CLIP）的测试时适应（TTA）方法，由于预训练数据偏置导致香农熵（SE）在不确定性估计中存在偏差。本文提出广义形式的Tsallis熵（TE）及其自适应去偏版本ADTE，通过引入非广延参数q并定制类特定参数，有效表征有偏分布，从而更准确地选择高置信度视图并增强适应性。实验证明，ADTE在多个基准测试上超越了现有SOTA方法，展现出优异的性能和鲁棒性，且对模型架构和文本提示不敏感。|Jianfeng Lu Team|[2602.11743](http://arxiv.org/abs/2602.11743)|null|
|**2026-02-12**|**Adapting Vision-Language Models for E-commerce Understanding at Scale**|电商产品理解需要强大的多模态（文本、图像、属性）能力，而通用视觉-语言模型（VLMs）虽具备通用建模潜力，但缺乏在不牺牲通用性能的前提下，针对电商数据特点（属性中心、多图像、高噪声）进行适应的策略。本研究通过大规模实验，证明了对通用VLM进行有针对性的适应能显著提升电商领域性能并保留广泛的多模态能力。此外，还提出了一个全面的评估套件，以深入衡量产品理解、指令遵循和动态属性提取能力。|Shahram Khadivi Team|[2602.11733](http://arxiv.org/abs/2602.11733)|null|
|**2026-02-12**|**STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning**|视觉-语言模型（VLMs）中文本与视觉坐标错位导致幻觉，尤其在时空视频定位（STVG）等密集预测任务中问题突出，且现有方法引入了额外的计算成本。本文提出一种新颖的视觉提示范式，将帧坐标预测重构为实例识别，通过为每个对象分配时间一致的ID并将其嵌入为视觉提示，为VLM提供显式输入。同时，引入首个用于STVG的强化学习框架STVG-R1，通过任务驱动奖励共同优化时空一致性。实验结果显示，STVG-R1在多个基准上取得SOTA性能，并在零样本多对象视频目标分割任务上展现出强大的泛化能力。|Qing Li Team|[2602.11730](http://arxiv.org/abs/2602.11730)|null|
|**2026-02-12**|**ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning**|大规模视觉指令微调（VIT）虽然提升了视觉-语言模型（VLMs）性能，但数据冗余导致训练效率低下，现有数据选择方法又面临计算成本高或可扩展性受限的问题。本文提出ScalSelect，一种可扩展的无训练多模态数据选择方法，其复杂度与样本数量呈线性关系。该方法通过提取模型对指令关注的视觉特征构建样本表示，并识别最能近似整个数据集主导子空间的样本，从而无需成对比较即可进行高效重要性评分。实验证明，ScalSelect仅用16%的数据即可达到全数据集训练97.5%以上的性能，在某些情况下甚至超越全数据训练。|Kai Chen Team|[2602.11636](http://arxiv.org/abs/2602.11636)|**[link](https://github.com/ChangtiWu/ScalSelect}{ScalSelect})**|
|**2026-02-12**|**SkillRater: Untangling Capabilities in Multimodal Data**|传统数据筛选将样本质量视为单一标量，无法同时优化模型所需的多种能力。本文提出SkillRater框架，将数据过滤分解为多个专门的评分器（每个能力一个），通过元学习在独立验证目标上训练。该框架采用渐进式选择规则，确保在训练早期保留多样性，后期聚焦高价值样本。在视觉语言模型上验证，将质量分解为视觉理解、OCR和STEM推理三个维度，SkillRater在基准测试上显著提升了各项能力。学习到的评分器信号几乎正交，证实了多维度分解的有效性，并解释了其优于单一过滤器的原因。|Akshat Shrivastava Team|[2602.11615](http://arxiv.org/abs/2602.11615)|null|
|**2026-02-12**|**Chatting with Images for Introspective Visual Thinking**|当前大型视觉-语言模型（LVLMs）主要依赖单次视觉编码的纯文本推理，导致细粒度视觉信息丢失，且现有“图像思考”方法在语言语义上 grounding 不足。本文提出“图像对话”框架，将视觉操作重新定义为语言引导的特征调制，在语言提示下，模型动态地对多个图像区域进行联合再编码，实现语言推理与视觉状态更新的紧密耦合。该范式在ViLaVT中实现，其动态视觉编码器专为交互式视觉推理设计，并通过两阶段课程训练。实验证明，ViLaVT在八个基准上取得显著提升，尤其在复杂多图像和视频空间推理任务上表现突出。|Tieniu Tan Team|[2602.11073](http://arxiv.org/abs/2602.11073)|null|
|**2026-02-11**|**Hierarchical Concept Embedding & Pursuit for Interpretable Image Classification**|现有的稀疏概念恢复方法在图像分类中忽视了概念的层次结构，可能导致解释与实际层次不符。本文提出分层概念嵌入与追踪（HCEP）框架，在潜在空间中诱导概念嵌入的层次结构，并利用分层稀疏编码来恢复图像中的概念。通过构建相应的概念嵌入层次结构，并假设正确概念形成根路径，HCEP能可靠地识别它们。实验表明，HCEP在概念精度和召回率方面优于基线，同时保持竞争性分类准确度，尤其在样本有限时表现更优，证明引入层次结构能提升模型可靠性和可解释性。|René Vidal Team|[2602.11448](http://arxiv.org/abs/2602.11448)|null|
|**2026-02-11**|**Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling**|扩散和流匹配模型的偏好优化需要鲁棒且高效的奖励函数，现有视觉-语言模型（VLMs）作为奖励提供者成本高昂，且像素空间奖励与潜在扩散生成器之间存在域不匹配。本文提出DiNa-LRM，一种扩散原生的潜在奖励模型，直接在带噪声的扩散状态上进行偏好学习。该方法引入了噪声校准的Thurstone似然，并利用预训练的潜在扩散骨干网络与时间步条件奖励头，支持推理时噪声集成。实验表明，DiNa-LRM在图像对齐任务上显著优于现有扩散基线，以远低于SOTA VLM的计算成本实现了相当的性能，并改进了偏好优化动态。|Wenhan Luo Team|[2602.11146](http://arxiv.org/abs/2602.11146)|**[link](https://github.com/HKUST-C4G/diffusion-rm)**|
|**2026-02-11**|**Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration**|现有视觉-语言模型（VLMs）的自我博弈方法依赖静态图像集的被动交互，导致学习效率低下且对初始数据集依赖性强。本文提出Active-Zero框架，将学习范式从被动交互转变为主动探索视觉环境。该框架包含三个协同进化的智能体：一个根据模型能力前沿检索图像的搜索器、一个合成校准推理任务的提问器、以及一个通过准确性奖励改进的求解器，形成自主构建学习轨迹的自适应课程。实验结果显示，Active-Zero在多个基准测试中显著提高了推理任务和通用理解的准确性，超越了现有自我博弈基线，证明主动探索是可扩展自进化VLM的关键。|Tat-Seng Chua Team|[2602.11241](http://arxiv.org/abs/2602.11241)|null|
|**2026-02-11**|**Safe mobility support system using crowd mapping and avoidance route planning using VLM**|自主移动机器人在动态、拥挤环境中导航面临挑战。本文提出一种新颖框架，将视觉-语言模型（VLM）与高斯过程回归（GPR）结合，生成动态人群密度图（“抽象图”）以辅助机器人导航。该方法利用VLM识别抽象环境概念（如人群密度），并通过GPR进行概率表示。真实世界试验结果表明，机器人成功规划了避开静态障碍物和动态人群的路线，有效提升了导航安全性和适应性。|Koichi Ozaki Team|[2602.10910](http://arxiv.org/abs/2602.10910)|null|

<p align=right>(<a href=#updated-on-20260213>back to top</a>)</p>

## VLA

| Publish Date | Title | Chinese Summary | Authors | PDF | Code |
|:---------|:-----------------------|:------------------------|:---------|:------|:------|
|**2026-02-12**|**Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment**|现有VLA模型在执行自然语言指令时存在“意图-动作”差距，导致生成的动作与指令不符。本文提出CoVer，一种测试时验证方法，通过联合扩展重述指令和生成动作数量来增加测试时样本多样性。该方法利用“启动时计算”和分层验证推理流程，预计算多样化指令并生成多个动作候选项，然后通过对比验证器选出最优动作。实验结果表明，CoVer在SIMPLER基准上取得了显著的性能提升，并在真实世界实验中实现了45%的额外改进，PolaRiS基准上任务进度和成功率亦有提高。|Marco Pavone Team|[2602.12281](http://arxiv.org/abs/2602.12281)|null|
|**2026-02-12**|**GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning**|由于场景理解和未来预期能力的限制，直接预测多步动作块的VLA模型存在固有局限。为解决此问题，本文提出了GigaBrain-0.5M*，一个通过基于世界模型的强化学习（RAMP）训练的VLA模型，其基础是预训练在大量机器人操作数据上的GigaBrain-0.5。RAMP整合了世界模型，旨在实现鲁棒的跨任务适应性。实验证明，GigaBrain-0.5M*在挑战性任务上比RECAP基线性能提升约30%，并能可靠地完成长周期复杂操作任务，无失败记录。|Zheng Zhu Team|[2602.12099](http://arxiv.org/abs/2602.12099)|**[link](https://gigabrain05m.github.io/)**|
|**2026-02-12**|**VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model**|提高VLA模型性能和可靠性面临真实世界策略轨迹数据收集成本高昂的问题。现有世界模型在物理保真度上不足，难以准确建模接触丰富的操作细节。本文提出一种迭代改进算法，利用少量真实世界轨迹数据来提升动作条件视频生成世界模型的保真度。进而，该改进后的世界模型被用于生成补充合成数据，以进一步优化VLA模型。在真实机器人上的实验表明，此方法使VLA模型在多个下游任务上的成功率绝对提高了39.2%，其中合成轨迹训练带来了11.6%的改进。|Chelsea Finn Team|[2602.12063](http://arxiv.org/abs/2602.12063)|null|
|**2026-02-12**|**HoloBrain-0 Technical Report**|为了弥合基础模型研究与可靠机器人部署之间的鸿沟，本文引入了HoloBrain-0，一个全面的VLA框架。其核心是一个新颖的VLA架构，通过显式融入多视角相机参数和运动学描述等机器人具身先验，增强3D空间推理并支持多样化具身。该框架采用“预训练-后训练”范式，并在模拟基准和真实世界长周期操作任务中实现了最先进的表现。HoloBrain生态系统已完全开源，包括预训练模型、后训练检查点以及用于数据管理、模型训练和部署的全栈基础设施RoboOrchard，以加速研究和实际应用。|Zhizhong Su Team|[2602.12062](http://arxiv.org/abs/2602.12062)|null|
|**2026-02-12**|**When would Vision-Proprioception Policies Fail in Robotic Manipulation?**|本体感觉信息对于机器人精确控制至关重要，但视觉-本体感觉策略在泛化性上存在不一致的观察。本文研究发现，在机器人运动过渡阶段，策略倾向于更快的本体感觉信号，抑制了视觉模态的学习。为解决此问题，提出梯度调整与阶段指导（GAP）算法，该算法根据本体感觉估计的运动过渡概率，自适应地调整本体感觉梯度的幅度，以实现视觉与本体感觉的动态协作。实验证明，GAP在模拟和真实世界环境中均能生成鲁棒且可泛化的视觉-本体感觉策略，并兼容多种设置和模型。|Di Hu Team|[2602.12032](http://arxiv.org/abs/2602.12032)|null|
|**2026-02-12**|**JEPA-VLA: Video Predictive Embedding is Needed for VLA Models**|当前VLA模型在机器人操作中面临样本效率低和泛化能力有限的问题，这与预训练视觉表示在环境理解和策略先验方面的不足密切相关。本文分析指出，现有视觉表示未能充分捕捉任务相关的环境信息和有效的策略先验。研究发现，预训练在视频上的预测嵌入（尤其是V-JEPA 2）能灵活地过滤不可预测因素并编码任务相关的时态动态。基于此，本文提出了JEPA-VLA，一种简单有效的方法，将预测嵌入自适应地集成到现有VLA中。实验结果表明，JEPA-VLA在一系列基准测试和真实机器人任务中取得了显著的性能提升。|Mingsheng Long Team|[2602.11832](http://arxiv.org/abs/2602.11832)|null|
|**2026-02-12**|**ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation**|具身导航任务长期被特定架构所割裂，缺乏统一性。本文提出了ABot-N0，一个统一的VLA基础模型，实现了点目标、物体目标、指令遵循、POI目标和人员跟随这五项核心任务的“大统一”。ABot-N0采用分层的“大脑-动作”架构，结合基于LLM的认知大脑进行语义推理和基于流匹配的动作专家进行精确轨迹生成。为支持大规模学习，研究团队构建了ABot-N0数据引擎，整理了海量专家轨迹和推理样本。实验结果显示，ABot-N0在7个基准测试中达到了新的SOTA性能，显著超越了专用模型，其代理导航系统也展现出在动态真实世界环境中执行长周期任务的鲁棒性。|Mu Xu Team|[2602.11598](http://arxiv.org/abs/2602.11598)|**[link](https://amap-cvlab.github.io/ABot-Navigation/ABot-N0/)**|
|**2026-02-12**|**Scaling World Model for Hierarchical Manipulation Policies**|VLA模型在通用机器人操作中前景广阔，但在分布外（OOD）场景中表现脆弱，尤其在真实机器人数据有限时。为解决泛化瓶颈，本文引入了VISTA，一个分层VLA框架，利用大规模预训练世界模型的泛化能力实现鲁棒且可泛化的视觉子目标任务分解。该框架包含一个作为高级规划器的世界模型和一个作为低级执行器的VLA，世界模型将任务分解为带有目标图像的子任务序列，低级策略依据文本和视觉指导生成动作。这些合成的目标图像为低级策略提供了具体细节，使其能泛化到未见物体和新场景。实验表明，在世界模型指导下，VLA在新型OOD场景中的性能从14%提升至69%，显著优于现有基线。|Xinghang Li Team|[2602.10983](http://arxiv.org/abs/2602.10983)|null|
|**2026-02-11**|**H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model**|世界模型在机器人规划和控制中能预测未来状态，但现有方法常难以直接关联机器人动作，并在长周期内累积误差。传统的符号逻辑世界模型虽然鲁棒，但缺乏视觉感知。本文提出了分层世界模型（H-WM），在一个统一的两级框架中联合预测逻辑和视觉状态转换。H-WM结合了高级逻辑世界模型和低级视觉世界模型，将符号推理的鲁棒性与视觉观察的感知基础相结合。为此，研究团队引入了一个对齐机器人运动、符号状态、动作和视觉观察的数据集进行训练。实验证明，分层输出为长周期任务提供了稳定一致的中间指导，有效减轻了误差积累，并在VLA控制策略上展现了有效性和通用性。|Yingxue Zhang Team|[2602.11291](http://arxiv.org/abs/2602.11291)|null|
|**2026-02-11**|**RISE: Self-Improving Robot Policy with Compositional World Model**|尽管VLA模型持续扩展，但在接触密集和动态操作任务中仍易失败。物理世界中的强化学习受限于安全风险和成本。为解决此问题，本文提出了RISE，一个通过想象进行机器人强化学习的可扩展框架。其核心是一个组合式世界模型，能够通过可控动态模型预测多视角未来，并利用进展价值模型评估想象结果。这些组件被整合到一个闭环自改进管道中，在想象空间中持续生成轨迹、估计优势并更新策略，无需昂贵的物理交互。RISE在三个挑战性的真实世界任务中取得了显著性能提升，例如在动态砖块分类中绝对性能提升超过35%。|Hongyang Li Team|[2602.11075](http://arxiv.org/abs/2602.11075)|**[link](https://opendrivelab.com/kai0-rl/)**|
|**2026-02-11**|**RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation**|现有视觉-语言-动作（VLA）模型在具身智能中取得进展，但其评估多限于仿真或受限真实环境，导致与真实世界存在巨大差距，泛化性差。针对这一问题，本文提出了RADAR基准，旨在系统评估VLA模型在真实条件下的泛化能力，其核心包含一套物理动态、明确测试空间推理和物理理解的任务，以及基于3D指标的完全自主评估管道。实验结果表明，RADAR能揭示SOTA VLA模型在物理动态下性能的严重下降和空间推理能力的局限性，证明其是评估VLA模型在真实世界中可靠性和泛化性的必要工具。|Guangrun Wang Team|[2602.10980](http://arxiv.org/abs/2602.10980)|null|
|**2026-02-11**|**From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving**|视觉-语言-动作（VLA）驾驶通过语言骨干网增强端到端规划，但其核心影响尚不明确。本文通过RecogDrive系统，使用VLM和纯视觉骨干网（均采用扩散Transformer规划器）进行了3个研究问题分析，探究了VLM引入的额外子空间及其在长尾场景中的行为差异。结果显示VLM引入了独特的行为子空间，在长尾场景中VLM更激进而ViT更保守，各有2-3%的场景表现优异。基于此，提出了HybridDriveVLA和DualDriveVLA，前者通过学习得分器结合ViT和VLM分支将PDMS提升至92.10，后者作为实用快慢策略，在15%场景调用VLM，在吞吐量提高3.2倍的同时实现了91.00 PDMS。|Yan Wang Team|[2602.10719](http://arxiv.org/abs/2602.10719)|null|
|**2026-02-11**|**Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation**|机器人操作中，现有系统普遍缺乏预测环境响应动作的演变能力，导致错误和低效，且现有世界模型预测范围短或生成空间不一致。为解决这些问题，本文提出了一个用于快速和预测性视频条件动作的框架。该方法首先选择并调整鲁棒的视频生成模型以进行可靠的未来预测，随后采用对抗蒸馏实现快速视频生成，最后训练一个动作模型，该模型结合生成视频和真实观测来纠正空间错误。实验结果表明，该方法生成的时间连贯、空间准确的视频预测能直接支持精确操作，并在具身一致性、空间指代能力和任务完成度方面显著优于现有基线。|Yanwei Fu Team|[2602.10717](http://arxiv.org/abs/2602.10717)|null|
|**2026-02-11**|**AugVLA-3D: Depth-Driven Feature Augmentation for Vision-Language-Action Models**|VLA模型在机器人感知与控制上取得进展，但多数依赖2D图像训练的VLM限制了其在复杂3D环境中的空间理解和动作接地。针对此，本文提出一种新框架，通过集成深度估计来丰富VLA模型的3D特征表示。具体方法是利用VGGT深度估计算法从RGB输入中提取几何感知的3D线索，并引入一个动作辅助模块，用动作先验约束3D表示以确保与下游控制任务的一致性。实验证明，该方法不仅增强了几何模糊场景的感知，还提升了动作预测准确性，凸显了深度驱动数据增强和辅助专家监督在弥合2D观测与3D决策之间鸿沟的潜力。|F. Richard Yu Team|[2602.10698](http://arxiv.org/abs/2602.10698)|null|
|**2026-02-11**|**Improving Medical Visual Reinforcement Fine-Tuning via Perception and Reasoning Augmentation**|强化微调（RFT）在大型语言模型后训练中表现出色，但其在跨模态、以视觉为中心的医学影像领域的应用仍待探索。为弥补这一空白，本文提出了VRFT-Aug，一个专为医学领域设计的视觉强化微调框架。该框架引入了多项训练策略，包括先验知识注入、感知驱动策略优化、医学知情奖励塑造和行为模仿，旨在稳定并改进RFT过程。在多个医学数据集上进行的广泛实验表明，VRFT-Aug持续优于标准的监督微调和RFT基线，并提供了可推广到其他医学图像任务的实用训练经验。|Qicheng Lao Team|[2602.10619](http://arxiv.org/abs/2602.10619)|null|
|**2026-02-11**|**LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer**|机器人领域长期目标是实现通用策略的零样本部署，但现有VLA模型与训练载体紧密耦合，需昂贵微调。本文提出了语言-动作预训练（LAP），一种通过自然语言直接表示低级机器人动作的方法，将动作监督与预训练视觉-语言模型的输入-输出分布对齐，无需学习tokenizer、昂贵标注或特定载体设计。基于LAP，提出LAP-3B，首次实现了向未见机器人载体的显著零样本迁移，平均成功率超过50%，较现有VLA提升约2倍。LAP还支持高效适应和扩展，并通过统一语言-动作格式实现协同训练增益。|Anirudha Majumdar Team|[2602.10556](http://arxiv.org/abs/2602.10556)|**[link](https://lap-vla.github.io)**|
|**2026-02-11**|**Found-RL: foundation model-enhanced reinforcement learning for autonomous driving**|强化学习（RL）是端到端自动驾驶（AD）的主导范式，但面临样本效率低下和语义可解释性不足的问题，而视觉-语言模型（VLM）可提供丰富的上下文感知知识。然而，VLM的高推理延迟阻碍了其在高速RL训练中的部署。为此，本文提出了Found-RL平台，通过异步批处理推理框架将VLM推理与仿真循环解耦，有效解决了延迟瓶颈。Found-RL引入了价值-裕度正则化和优势加权动作指导等监督机制，将VLM专家建议有效蒸馏到RL策略中，并通过条件对比动作对齐利用CLIP进行密集奖励塑造。实验表明，轻量级RL模型可实现接近十亿参数VLM的性能，同时保持实时推理（约500 FPS）。|Sikai Chen Team|[2602.10458](http://arxiv.org/abs/2602.10458)|null|
|**2026-02-10**|**Hardware Co-Design Scaling Laws via Roofline Modelling for On-Device LLMs**|视觉-语言-动作模型（VLA）在设备端部署时，需平衡模型准确性与严格的推理延迟及硬件效率，硬件-软件协同设计至关重要。本文提出了一种硬件协同设计法则，联合捕捉模型准确性和推理性能。通过将训练损失建模为架构超参数函数，并利用屋脊线模型刻画推理延迟，建立了直接的准确性-延迟对应关系，并识别了硬件协同设计LLM的帕累托前沿。该方法将架构选择时间从数月缩短到数天，在相同延迟下，协同设计的架构在WikiText-2上的困惑度比Qwen2.5-0.5B降低19.42%。该工作首次提供了设备上LLM部署中硬件协同设计缩放定律的原则性框架。|Cheng Deng Team|[2602.10377](http://arxiv.org/abs/2602.10377)|null|
|**2026-02-10**|**ST4VLA: Spatially Guided Training for Vision-Language-Action Models**|大型视觉-语言模型（VLM）虽擅长多模态理解，但在具身任务中将其指令转化为低级动作时表现不佳。为此，本文提出了ST4VLA，一个双系统视觉-语言-动作框架，利用空间引导训练将动作学习与VLM中的空间先验对齐。ST4VLA包含空间接地预训练和空间引导动作后训练两个阶段，前者通过点、框和轨迹预测为VLM提供可迁移先验，后者鼓励模型通过空间提示生成更丰富的空间先验以指导动作生成。实验结果表明，ST4VLA在Google Robot和WidowX Robot上性能显著提升，并在SimplerEnv上刷新SOTA，同时对未见物体、释义指令和真实世界扰动表现出更强的泛化性和鲁棒性。|Jiangmiao Pang Team|[2602.10109](http://arxiv.org/abs/2602.10109)|null|
|**2026-02-10**|**EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration**|人类演示数据作为机器人远程操作的替代方案潜力巨大，但其在人形机器人运动-操作这一数据密集型挑战中的应用仍未充分探索。本文提出了EgoHumanoid框架，首次将大量以自我为中心的人类演示与有限机器人数据共同训练视觉-语言-动作策略，使人形机器人能在多样真实环境中执行运动-操作任务。为弥合人类与机器人间的具身鸿沟，该框架引入了从硬件设计到数据处理的系统对齐管道，特别是视点对齐和动作对齐两个核心组件。广泛的真实世界实验表明，整合无机器人自我中心数据显著优于仅机器人基线51%，尤其是在未见环境中，并揭示了人类数据有效迁移和扩展的潜力。|Li Chen Team|[2602.10106](http://arxiv.org/abs/2602.10106)|**[link](https://opendrivelab.com/EgoHumanoid)**|

<p align=right>(<a href=#updated-on-20260213>back to top</a>)</p>

## Humanoid

| Publish Date | Title | Chinese Summary | Authors | PDF | Code |
|:---------|:-----------------------|:------------------------|:---------|:------|:------|
|**2026-02-12**|**General Humanoid Whole-Body Control via Pretraining and Fast Adaptation**|针对人形机器人全身控制在运动多样性、快速适应和高动态平衡方面的挑战，本研究提出了FAST框架。该框架通过Parseval-Guided Residual Policy Adaptation学习轻量级策略以高效适应分布外运动并减轻灾难性遗忘，同时引入Center-of-Mass-Aware Control提升物理鲁棒性。仿真和真实世界实验表明，FAST在鲁棒性、适应效率和泛化能力上均优于现有基线。|Zongqing Lu Team|[2602.11929](http://arxiv.org/abs/2602.11929)|null|
|**2026-02-12**|**HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model**|为解决人形机器人在人机交互中对具有独立动力学和非完整约束的欠驱动物体进行操作的挑战，本研究提出了HAIC框架。该框架通过一个仅利用本体感知历史的动力学预测器估计高阶物体状态，并将其投射到静态几何先验形成动态占用图，使机器人能在盲区推断接触信息。通过非对称微调，HAIC在人形机器人上实现了对欠驱动物体的高成功率敏捷任务（如滑板），并能完成多物体长时序任务。|Renjing Xu Team|[2602.11758](http://arxiv.org/abs/2602.11758)|**[link](https://haic-humanoid.github.io/)**|
|**2026-02-12**|**Future Mining: Learning for Safety and Security**|鉴于恶劣采矿环境对感知、态势感知和分布式学习的严峻挑战，以及日益增长的网络物理安全威胁，本研究提出了一个统一的智能安全与安保架构愿景。该架构整合了多模态感知、安全联邦学习、强化学习、延迟容忍网络通信和能源感知传感，包含矿工定位、多模态态势感知等五个核心模块。此框架旨在构建一个弹性、可信的智能采矿系统，以应对对抗性条件下的运营挑战并确保任务关键设备的可靠性。|Sanjay Madria Team|[2602.11472](http://arxiv.org/abs/2602.11472)|null|
|**2026-02-12**|**Humanoid Manipulation Interface: Humanoid Whole-Body Manipulation from Robot-Free Demonstrations**|当前人形机器人全身操作方法受限于硬件和奖励工程，导致自主技能有限且多在受控环境。本研究提出了Humanoid Manipulation Interface (HuMI)，一个便携高效的框架，旨在学习多种环境中的多样化全身操作任务。HuMI通过便携式硬件捕捉人类全身运动数据，实现了无机器人数据采集，并利用分层学习管道将人类动作转化为灵巧可行的人形机器人技能。实验表明，HuMI的数据采集效率比遥操作提高了3倍，并在未见环境中达到了70%的成功率。|Yang Gao Team|[2602.06643](http://arxiv.org/abs/2602.06643)|**[link](https://humanoid-manipulation-interface.github.io)**|
|**2026-02-11**|**ExtremControl: Low-Latency Humanoid Teleoperation with Direct Extremity Control**|针对现有遥操作系统在人形机器人上存在高延迟、限制快速响应的问题，本研究提出了ExtremControl低延迟全身控制框架。该方法直接在选定肢端的SE(3)姿态上操作，避免了全身运动重定向，并通过笛卡尔空间映射和低层速度前馈控制实现高响应性。理论和实验验证表明，ExtremControl实现了低至50ms的端到端延迟，显著超越了以往工作，成功支持了如乒乓球平衡等需要快速反应的高动态任务。|Chuang Gan Team|[2602.11321](http://arxiv.org/abs/2602.11321)|**[link](https://owenowl.github.io/extremcontrol)**|
|**2026-02-11**|**APEX: Learning Adaptive High-Platform Traversal for Humanoid Robots**|为解决人形机器人难以安全有效地攀爬超过腿长的高平台的问题，本研究提出了APEX系统。该系统通过组合多种地形条件行为（攀爬、行走、姿态调整），并引入广义棘轮进度奖励来训练接触丰富的目标达成机动，同时利用LiDAR感知和双重策略减小仿真到真实的感知差距。在Unitree G1人形机器人上的实验表明，APEX实现了0.8米高平台的零样本仿真到真实穿越，展现出鲁棒的平台高度和初始姿态适应性及平滑的多技能转换能力。|Ding Zhao Team|[2602.11143](http://arxiv.org/abs/2602.11143)|**[link](https://apex-humanoid.github.io/)**|
|**2026-02-11**|**Towards Learning a Generalizable 3D Scene Representation from 2D Observations**|为解决现有神经辐射场方法在机器人操作中对3D工作空间占用预测的局限性，本研究提出了一种可泛化的神经辐射场方法。该模型在全局工作空间框架中构建占用表示，使其能直接应用于机器人操作，并通过整合灵活的源视图实现对未见物体排列的泛化，无需场景特定微调。在人形机器人上的实验结果显示，该模型在包含遮挡区域的情况下实现了26mm的重建误差，验证了其超越传统立体视觉方法的完整3D占用推断能力。|Stefan Wermter Team|[2602.10943](http://arxiv.org/abs/2602.10943)|null|
|**2026-02-11**|**MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation**|针对通用人形机器人运动追踪器在硬件上持续遥操作时易受接口和动力学误差影响的问题，本研究提出了MOSAIC，一个开源、全栈的运动追踪与全身遥操作系统。MOSAIC通过强化学习训练通用运动追踪器，并采用自适应重采样和强调世界坐标系运动一致性的奖励。为弥合仿真到真实接口差距，系统采用快速残差适应机制，通过接口特定数据训练残差模块并将其蒸馏到通用追踪器。实验验证了MOSAIC在真实延迟和噪声下的鲁棒离线运动回放和在线长时程遥操作能力。|Alois Knoll Team|[2602.08594](http://arxiv.org/abs/2602.08594)|null|
|**2026-02-10**|**EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration**|针对人形机器人运动-操作任务中数据饥渴和人机本体差异问题，本研究提出了EgoHumanoid框架。该框架首次共同训练了一个视觉-语言-动作策略，融合了大量的自我中心人体演示数据和有限的机器人数据，并设计了从硬件到数据处理的系统对齐管线，包括视图对齐和动作对齐。实验结果表明，该方法在多样化真实环境中显著提升了人形机器人的运动-操作性能，尤其是在未见过的新环境中，超越了仅使用机器人数据的基线模型51%。|Li Chen Team|[2602.10106](http://arxiv.org/abs/2602.10106)|**[link](https://opendrivelab.com/EgoHumanoid)**|
|**2026-02-10**|**Humanoid Factors: Design Principles for AI Humanoids in Human Worlds**|随着人形机器人逐渐与人类共享工作和生活空间，设计挑战从传统“人类因素”扩展至“人形机器人因素”。本研究引入了“人形机器人因素”框架，围绕物理、认知、社交和伦理四大支柱，旨在指导人形机器人开发，促使其与人类有效共存与协作。该框架通过评估真实机器人控制算法，揭示了传统机器人指标对人类认知和交互原则的忽视，为设计、评估和管理持续人机共存提供了基础性指导。|Lixiao Huang Team|[2602.10069](http://arxiv.org/abs/2602.10069)|null|
|**2026-02-10**|**TeleGate: Whole-Body Humanoid Teleoperation via Gated Expert Selection with Motion Prior**|为解决实时全身遥操作中统一控制器在多样化人体运动上性能下降的挑战，本研究提出了TeleGate框架。该框架通过训练一个轻量级门控网络，根据本体感知状态和参考轨迹动态激活领域特定专家策略，以避免知识蒸馏带来的性能损失。此外，引入VAE基运动先验模块从历史观测中提取未来运动意图，实现前瞻性控制。实验结果表明，TeleGate在Unitree G1人形机器人上仅用2.5小时动捕数据，便在多种动态运动（如跑步、跌倒恢复、跳跃）中实现了高精度实时遥操作，显著优于基线方法。|Rongyun Cao Team|[2602.09628](http://arxiv.org/abs/2602.09628)|null|
|**2026-02-09**|**Characteristics, Management, and Utilization of Muscles in Musculoskeletal Humanoids: Empirical Study on Kengoro and Musashi**|当前肌肉骨骼人形机器人研究在利用其仿生优势方面取得了进展，但对其多样化特性及管理利用方法缺乏统一深入讨论。本研究基于Kengoro和Musashi机器人，将肌肉骨骼结构特征归纳为冗余性、独立性、各向异性、可变力臂和非线性弹性五类。在此基础上，文章分析了这些特性组合带来的优缺点，并讨论了身体图式学习、反射控制、肌肉分组和身体图式适应的实现，为未来研究方向提供了展望。|Masayuki Inaba Team|[2602.08518](http://arxiv.org/abs/2602.08518)|null|
|**2026-02-09**|**Learning Human-Like Badminton Skills for Humanoid Robots**|人形机器人在羽毛球等高要求运动中实现类人表现面临挑战，需要爆发性的全身协调和精确拦截，同时保持运动自然性。本研究提出了“模仿到交互”的渐进式强化学习框架，通过从人类数据建立运动先验、模型化状态表示和对抗性先验来稳定动态，并引入流形扩展策略解决专家演示稀疏性问题。该框架在仿真中掌握了多样技能，并首次成功实现拟人化羽毛球技能从仿真到真实人形机器人的零样本迁移，展现了人类运动员的动能优雅和功能精度。|Peng Lu Team|[2602.08370](http://arxiv.org/abs/2602.08370)|null|
|**2026-02-07**|**VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots**|现有的人形机器人面部表情模仿系统因离线推理和对细微表情细节捕捉不足，难以同时达到实时性和逼真表现力。本研究提出了VividFace，一个实时、逼真的人形机器人面部表情影子系统。该系统通过优化X2CNet++框架以增强面部运动转移的准确性，并采用特征适应训练策略，同时利用视频流兼容推理管道和异步I/O实现实时性能。VividFace能在0.05秒内模仿人类表情并生成生动的人形面部，已通过广泛的真实世界演示验证了其实用性。|Yang Zhang Team|[2602.07506](http://arxiv.org/abs/2602.07506)|null|
|**2026-02-07**|**TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control**|人形机器人全身运动控制受限于预定义轨迹或持续遥操作，缺乏灵活性和自主性。本研究提出了TextOp，一个实时文本驱动的人形机器人运动生成与控制框架，支持流式语言命令和即时指令修改。该框架采用两级架构，高级自回归运动扩散模型根据文本生成短时域运动学轨迹，低级策略则在物理机器人上执行这些轨迹。真实机器人实验表明TextOp具有即时响应性、流畅全身运动和精确控制，能实现多种复杂行为间的平稳过渡。|Xuelong Li Team|[2602.07439](http://arxiv.org/abs/2602.07439)|**[link](https://text-op.github.io/)**|
|**2026-02-07**|**Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots**|有效的人机交互需要情感丰富的多模态表达，但现有机器人缺乏语音、面部表情和姿态的协调，且实际部署要求设备端自主运行。本研究提出了SeM²框架，一个基于视觉语言模型（VLM）的框架，通过多模态感知、思维链推理和新型语义序列对齐机制（SSAM）协调情感一致的多模态交互。框架提供了云端和边缘部署版本，后者通过知识蒸馏高效运行。综合评估证明SeM²在自然性、情感清晰度和模态一致性方面显著优于基线，推动了社交表达型人形机器人发展。|Miao Li Team|[2602.07434](http://arxiv.org/abs/2602.07434)|null|
|**2026-02-06**|**Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation**|机器人策略在真实世界部署后常面临故障，而重新训练或系统识别并不总是可行。本研究提出了一种受小脑启发的推理时残差控制框架，通过在线校正动作增强冻结的强化学习策略，无需修改基础策略参数即可实现故障恢复。该框架利用高维模式分离、并行残差路径和误差驱动可塑性等机制，并通过元适应调节残差权限。在MuJoCo基准测试中，该方法在执行器、动态和环境扰动下，对HalfCheetah-v5和Humanoid-v5分别实现了高达+66%和+53%的性能提升，且在严重故障下仍能优雅降级。|Amit Ranjan Trivedi Team|[2602.07227](http://arxiv.org/abs/2602.07227)|null|
|**2026-02-06**|**DynaRetarget: Dynamically-Feasible Retargeting using Sampling-Based Trajectory Optimization**|将人类运动重定向至人形机器人控制策略并生成动态可行运动是一个挑战。本研究引入了DynaRetarget，一个完整的人类运动到人形机器人控制策略的重定向流程。其核心是新型基于采样的轨迹优化（SBTO）框架，能够将不完美的运动学轨迹精炼为动态可行的运动，并通过增量优化实现长时域任务的轨迹优化。实验验证DynaRetarget在重定向数百个人形机器人与物体交互演示时取得了更高的成功率，并能泛化到不同物体属性，为生成大规模合成数据集提供了可能。|Majid Khadiv Team|[2602.06827](http://arxiv.org/abs/2602.06827)|null|
|**2026-02-06**|**ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking**|实现人形机器人稳定、节能的运动对于实际应用至关重要，但现有方法常将能量指标嵌入多目标优化中，导致超参数调整复杂且易得次优策略。本研究提出了ECO（Energy-Constrained Optimization），一个约束强化学习框架，将能量相关指标作为显式不等式约束。该方法通过拉格朗日乘子法对能量消耗和参考运动施加专用约束，以实现人形机器人的稳定、对称和节能行走。在与多种SOTA方法的对比评估和模拟到真实迁移实验中，ECO在保持鲁棒行走性能的同时显著降低了能耗。|Yao Su Team|[2602.06445](http://arxiv.org/abs/2602.06445)|null|
|**2026-02-06**|**Now You See That: Learning End-to-End Humanoid Locomotion from Raw Pixels**|基于视觉的人形机器人稳定运动面临模拟到真实差距造成的感知噪声和不同地形下学习目标冲突的挑战。本研究提出了一个端到端的视觉驱动人形机器人运动框架。为克服模拟到真实差距，开发了高保真深度传感器模拟并提出视觉感知行为蒸馏方法，结合潜在空间对齐和噪声不变辅助任务。为适应多样地形，引入地形特定奖励整形并集成了多评论家和多判别器学习。在配备不同立体深度摄像头的两个人形平台上的验证显示，该策略在处理极端挑战和精细任务时表现出强大的鲁棒性。|Zongwu Xie Team|[2602.06382](http://arxiv.org/abs/2602.06382)|null|

<p align=right>(<a href=#updated-on-20260213>back to top</a>)</p>
