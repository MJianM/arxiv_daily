## Updated on 2026.02.15

## Categories

- [Manipulation](#manipulation)
- [World Model](#world-model)
- [VLM](#vlm)
- [VLA](#vla)
- [Humanoid](#humanoid)

## Manipulation

|Publish Date|Title|Chinese Summary|Authors|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-12**|**FAIL: Flow Matching Adversarial Imitation Learning for Image Generation**|为解决流匹配模型后训练中监督微调无法纠正策略漂移及偏好优化成本高的问题，本文提出了流匹配对抗模仿学习（FAIL）。该方法通过对抗训练最小化策略与专家演示之间的分歧，无需显式奖励或配对比较，并推导了基于可微分ODE求解器的FAIL-PD和黑盒替代方案FAIL-PG。实验结果表明，仅使用少量演示数据，FAIL在提示跟随和美学基准上表现出竞争力，并能有效泛化至离散图像与视频生成，还能作为正则化器缓解奖励劫持。|Weidi Xie Team|[2602.12155](http://arxiv.org/abs/2602.12155)|null|
|**2026-02-12**|**GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning**|针对现有视觉-语言-动作（VLA）模型在场景理解和未来预测方面的局限性，本文提出了GigaBrain-0.5M*，一个基于世界模型强化学习训练的VLA模型。该模型构建于预训练的GigaBrain-0.5之上，并整合了RAMP（通过世界模型条件策略的强化学习）以实现鲁棒的跨任务适应。实验证明，RAMP在RECAP基线上实现了显著的性能提升，在具有挑战性的操作任务中性能提高了约30%，并且GigaBrain-0.5M*在实际部署中展示了可靠的长期执行能力。|Zheng Zhu Team|[2602.12099](http://arxiv.org/abs/2602.12099)|**[link](https://gigabrain05m.github.io/)**|
|**2026-02-12**|**Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning**|鉴于在真实世界中训练机器人策略的高成本和现有生成模拟方法在生成逻辑连贯的长期任务及处理动态物理不确定性方面的不足，本文提出了Affordance-Graphed Task Worlds (AGT-World) 框架。该框架能基于真实世界观测自主构建交互式模拟环境和机器人任务策略，通过将任务空间形式化为结构化图实现复杂目标的分层分解，并引入带有混合反馈的自进化机制来完善策略。实验结果表明，AGT-World在成功率和泛化能力上显著优于现有方法，实现了可扩展机器人学习的自改进循环。|Changshui Zhang Team|[2602.12065](http://arxiv.org/abs/2602.12065)|null|
|**2026-02-12**|**HoloBrain-0 Technical Report**|为了弥合基础模型研究与可靠机器人部署之间的差距，本文推出了HoloBrain-0，一个全面的视觉-语言-动作（VLA）框架。该系统核心在于其新颖的VLA架构，通过显式整合机器人具身先验（如多视角相机参数和URDF）来增强3D空间推理并支持多样化具身。通过“预训练-后训练”范式验证，HoloBrain-0在模拟基准上取得了最先进结果，并在真实世界长期操作任务中表现出色，其高效的0.2B参数变体能实现低延迟部署，并且整个生态系统已完全开源以加速研究和应用。|Zhizhong Su Team|[2602.12062](http://arxiv.org/abs/2602.12062)|null|
|**2026-02-12**|**When would Vision-Proprioception Policies Fail in Robotic Manipulation?**|针对视觉-本体感受策略在泛化性方面的不一致观察，本文通过时序控制实验发现，在机器人运动转换阶段，视觉模态的作用有限，策略倾向于本体感受信号以实现更快的损失下降。为解决此问题，本文提出了梯度调整与阶段引导（GAP）算法，通过利用本体感受估计运动转换阶段的概率，并自适应地降低本体感受的梯度幅度，从而实现视觉与本体感受模态间的动态协作。综合实验表明，GAP在多种机器人设置和模型中均能提升策略的鲁棒性和泛化能力。|Di Hu Team|[2602.12032](http://arxiv.org/abs/2602.12032)|null|
|**2026-02-12**|**Accelerating Robotic Reinforcement Learning with Agent Guidance**|面对强化学习在现实世界机器人操作中样本效率低下及人机交互（HIL）方法面临的可扩展性瓶颈和高方差问题，本文提出了Agent-guided Policy Search (AGPS) 框架。AGPS通过多模态智能体取代人类监督者，将智能体视为语义世界模型，注入内在价值先验来引导物理探索，并利用可执行工具提供精确的校正路点和空间约束。实验结果表明，AGPS在样本效率上优于HIL方法，从而自动化了监督流程，为实现无需人力的可扩展机器人学习开辟了道路。|Yaodong Yang Team|[2602.11978](http://arxiv.org/abs/2602.11978)|null|
|**2026-02-12**|**Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control**|本文认为，泛化机器人操作的关键瓶颈在于现有视觉骨干网络与闭环控制所需几何敏感性之间的结构不匹配。为弥补判别式视觉编码器在精细控制上的“盲点”和直接使用生成扩散模型特征进行控制的局限性，本文提出了Robot-DIFT框架。该框架通过流形蒸馏将冻结的扩散教师模型蒸馏至确定性空间-语义特征金字塔网络（S2-FPN），从而在保持生成模型丰富几何先验的同时，确保时间稳定性、实时执行和鲁棒性。实验证明，Robot-DIFT在几何一致性和控制性能上优于领先的判别式基线。|Georgia Chalvatzaki Team|[2602.11934](http://arxiv.org/abs/2602.11934)|null|
|**2026-02-12**|**JEPA-VLA: Video Predictive Embedding is Needed for VLA Models**|尽管基于预训练视觉-语言模型的VLA模型在机器人操作中取得了进展，但仍面临样本效率低和泛化能力有限的问题，这主要归因于现有预训练视觉表示在环境理解和策略先验方面的不足。本文深入分析发现，视频上预训练的预测性嵌入（特别是V-JEPA 2）能有效捕获任务相关的时序动态并灵活舍弃不可预测因素。基于此，本文提出了JEPA-VLA，一个将预测性嵌入自适应集成到现有VLA中的方法。实验结果显示，JEPA-VLA在LIBERO、LIBERO-plus、RoboTwin2.0和真实机器人任务等基准上均实现了显著的性能提升。|Mingsheng Long Team|[2602.11832](http://arxiv.org/abs/2602.11832)|null|
|**2026-02-12**|**Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes**|针对杂乱环境中3D实例分割在遮挡、有限视角和噪声掩码下的挑战，本文提出了Clutt3R-Seg，一个零样本、鲁棒的3D实例分割流程，用于语言引导的抓取。该方法的核心是构建一个语义线索的分层实例树，并利用噪声掩码作为信息线索，通过跨视图分组和条件替换来生成视图一致的掩码和鲁棒的3D实例。为处理场景变化，引入了一致性感知更新机制。实验证明，Clutt3R-Seg在杂乱和稀疏视图场景中显著优于现有基线，尤其在重度杂乱序列中表现出2.2倍以上的性能提升。|Ayoung Kim Team|[2602.11660](http://arxiv.org/abs/2602.11660)|null|
|**2026-02-12**|**ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning**|鉴于触觉信息在机器人操作中的重要性，以及现有方法在处理遮挡场景时因忽视视觉与触觉互补性而效果不佳的问题，本文提出了ViTaS框架。该框架通过引入软融合对比学习（Soft Fusion Contrastive Learning）和CVAE模块，有效利用视觉-触觉表示中的对齐与互补性来指导智能体行为。在12个模拟和3个真实世界环境中的实验结果表明，ViTaS显著优于现有基线方法，证明了其在结合视觉和触觉信息方面的有效性。|Huazhe Xu Team|[2602.11643](http://arxiv.org/abs/2602.11643)|null|
|**2026-02-12**|**EasyMimic: A Low-Cost Framework for Robot Imitation Learning from Human Videos**|机器人模仿学习面临真实世界数据收集成本高昂的挑战，尤其对于低成本家用机器人。为此，本研究提出了EasyMimic框架，一种经济且可复现的解决方案。该方法通过标准RGB相机捕获人类视频演示，提取3D手部轨迹，并利用动作对齐模块将其映射到低成本机器人的抓手控制空间，同时引入手部视觉增强策略以弥合人机领域差距。通过在处理过的人类数据和少量机器人数据上进行协同训练，模型能够快速适应新任务。实验表明，EasyMimic在多种操作任务中表现出色，显著减少了对昂贵机器人数据收集的依赖。|Qin Jin Team|[2602.11464](http://arxiv.org/abs/2602.11464)|null|
|**2026-02-12**|**Scaling World Model for Hierarchical Manipulation Policies**|视觉-语言-动作（VLA）模型在通用机器人操作中虽有前景，但在有限真实机器人数据下，其在分布外（OOD）场景中的泛化能力仍脆弱。本研究提出VISTA，一个分层视觉-语言-动作框架，利用大规模预训练世界模型的泛化能力实现鲁棒且可泛化的视觉子目标任务分解。该框架将世界模型作为高层规划器来生成带有目标图像的子任务序列，VLA作为低层执行器遵循指导生成动作。实验结果表明，与原始文本目标相比，合成的目标图像提供了更具视觉和物理细节的指导，使低层策略能泛化到新物体和场景，将VLA在OOD场景中的性能从14%提升至69%。|Xinghang Li Team|[2602.10983](http://arxiv.org/abs/2602.10983)|null|
|**2026-02-11**|**Human Preference Modeling Using Visual Motion Prediction Improves Robot Skill Learning from Egocentric Human Video**|当前从第一视角人类视频中学习机器人的方法，在度量视觉状态长期价值时存在假设限制，且在跨实体和环境时需要迁移学习到的价值函数。本研究提出一种新方法，通过预测后续图像中跟踪点的运动来建模人类偏好，并将奖励函数定义为机器人行为中预测与观察到的物体运动的一致性。随后，利用改进的Soft Actor Critic (SAC) 算法（通过10次机器人演示初始化）来估计此奖励的价值函数，并在机器人上优化策略。结果显示，该方法在真实机器人上有效，并且在模拟和真实机器人上的多项任务中，其学习到的策略与现有工作相当或超越。|Christopher G. Atkeson Team|[2602.11393](http://arxiv.org/abs/2602.11393)|null|
|**2026-02-11**|**MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation**|机器人大规模部署要求对日常情境具备鲁棒性，但现有基准测试缺乏足够多样化的场景。本研究引入了MolmoSpaces，一个支持机器人策略大规模基准测试的开放生态系统，包含超过23万个多样化室内环境和13万个丰富注释的物体资产，且与模拟器无关。同时设计了MolmoSpaces-Bench基准套件。实验证明，MolmoSpaces-Bench具有强大的模拟到真实关联性，验证了新型零样本策略的优越性，并揭示了对提示措辞、初始关节位置和相机遮挡的关键敏感性，为机器人学习研究提供了可扩展的基础。|Ranjay Krishna Team|[2602.11337](http://arxiv.org/abs/2602.11337)|null|
|**2026-02-11**|**YOR: Your Own Mobile Manipulator for Generalizable Robotics**|随着机器人学习的发展，低成本机器人平台日益增多，但移动操作的最佳外形仍然是待解问题。本研究推出YOR，一个开源、低成本的移动操纵器，集成了全向基座、伸缩式垂直升降器和带抓手的双臂，以实现全身移动和操作。其设计强调模块化、易于组装和经济性（物料清单成本低于1万美元）。YOR在需要协调全身控制、双臂操作和自主导航的任务中展现出其能力，以远低于现有平台的成本提供了具有竞争力的移动操作研究功能。|Zichen Jeff Cui Team|[2602.11150](http://arxiv.org/abs/2602.11150)|null|
|**2026-02-11**|**ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning**|在异构硬件上构建通用具身智能体是机器人学的一大挑战，面临数据碎片化、表示不一致和训练目标不匹配等问题。本研究提出了ABot-M0框架，它通过建立系统的数据整理管道，同时优化模型架构和训练策略，将异构原始数据转换为统一、高效的表示。通过构建大规模UniACT数据集，统一预训练提高了跨平台和任务的知识迁移和泛化能力。为提升动作预测效率和稳定性，引入了动作流形学习（AML）。此外，框架通过双流机制实现模块化感知，整合VLM语义与几何先验和多视角输入。实验结果表明各组件独立且具有累加效益。|Mu Xu Team|[2602.11236](http://arxiv.org/abs/2602.11236)|**[link](https://amap-cvlab.github.io/ABot-Manipulation/)**|
|**2026-02-11**|**OSIL: Learning Offline Safe Imitation Policies with Safety Inferred from Non-preferred Trajectories**|离线安全模仿学习面临在缺乏每时间步安全成本或奖励信息的演示数据中学习安全和奖励最大化策略的难题。本研究针对此问题提出了一种新颖的离线安全模仿学习算法OSIL，它通过非首选轨迹推断安全性。OSIL将安全策略学习表述为约束马尔可夫决策过程（CMDP），并通过推导奖励最大化目标的下界并学习一个估计非首选行为可能性的成本模型来重新构建CMDP问题，从而无需明确的安全成本和奖励标注。实验证明，OSIL能学习到更安全的策略，满足成本约束而不降低奖励性能，优于现有基线方法。|Balaraman Ravindran Team|[2602.11018](http://arxiv.org/abs/2602.11018)|null|
|**2026-02-11**|**Towards Learning a Generalizable 3D Scene Representation from 2D Observations**|现有方法在相机坐标系中构建表示，限制了其在机器人操作中的直接应用。本研究引入了一种可泛化的神经辐射场方法，用于根据以机器人自我为中心的观察来预测3D工作空间占用。该模型在全局工作空间框架中构建占用表示，使其直接适用于机器人操作，并能集成灵活的源视图，无需场景特定微调即可泛化到未见物体布局。在人形机器人上的实验证明，该模型在40个真实场景上训练后，实现了26毫米的重建误差（包括遮挡区域），验证了其推断完整3D占用（超越传统立体视觉方法）的能力。|Stefan Wermter Team|[2602.10943](http://arxiv.org/abs/2602.10943)|null|
|**2026-02-11**|**Semi-Supervised Cross-Domain Imitation Learning**|跨域模仿学习（CDIL）通过领域知识迁移加速策略学习，但在专家数据收集成本高昂时尤为重要。现有CDIL方法或依赖监督（不稳定），或无监督（不稳健）。本研究提出了半监督CDIL（SS-CDIL）设置及其首个具有理论依据的算法。该方法仅使用少量目标专家演示和未标记的不完善轨迹等离线数据。为解决域差异，提出一种新颖的跨域损失函数来学习域间状态-动作映射，并设计自适应权重函数以平衡源域和目标域知识。实验表明，该方法在MuJoCo和Robosuite上始终优于基线，实现了最小监督下稳定且数据高效的策略学习。|Ping-Chun Hsieh Team|[2602.10793](http://arxiv.org/abs/2602.10793)|null|
|**2026-02-11**|**Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation**|机器人操作通常缺乏预测环境响应动作的能力，导致错误和低效，且现有视觉-语言模型（VLM）和世界模型在预测未来状态或生成空间一致帧方面存在局限。本研究提出一种用于快速且可预测的视频条件动作框架。该方法首先选择并适应一个鲁棒的视频生成模型以确保可靠的未来预测，然后应用对抗蒸馏进行快速、少步骤的视频生成，最后训练一个动作模型，利用生成的视频和真实观察来纠正空间误差。大量实验表明，该方法生成的时间连贯、空间准确的视频预测直接支持精确操作，在具身一致性、空间指代能力和任务完成度方面显著优于现有基线。|Yanwei Fu Team|[2602.10717](http://arxiv.org/abs/2602.10717)|null|

<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>

## World Model

|Publish Date|Title|Chinese Summary|Authors|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-12**|**The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics**|在评估神经网络模型是否真正内化物理定律而非利用统计捷径时，特别是在分布外（OOD）测试中，挑战重重。传统的适应性评估可能改变表征，混淆模型学到的内容。为此，研究提出了一种非侵入性评估协议PhyIP，通过检测物理量是否可从冻结表征中线性解码，以验证线性表征假设。实验表明，在流体动力学和轨道力学任务中，当自监督学习（SSL）达到低误差时，潜在结构变得线性可访问，PhyIP在OOD测试中成功恢复了内能和牛顿平方反比定律（ρ>0.90）。相反，基于适应性的评估可能导致这种结构崩溃（ρ≈0.05）。这表明低容量探针能更准确地评估物理世界模型。|Barbara Hammer Team|[2602.12218](http://arxiv.org/abs/2602.12218)|null|
|**2026-02-12**|**LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion**|现有机器人基础模型主要依赖行为克隆，忽视了异构具身数据中蕴含的可迁移动力学知识，且统一世界模型（UWM）在扩展至基础模型层面时面临数据使用粗糙和数据集碎片化的问题。本研究提出LDA-1B，一个通过通用具身数据摄取进行扩展的机器人基础模型，它联合学习动力学、策略和视觉预测，并为不同质量的数据分配角色。为支持大规模学习，构建了包含3万小时轨迹的EI-30k数据集，并通过在结构化DINO潜在空间中预测来实现可扩展的动力学学习，同时采用多模态扩散Transformer处理异步数据流。实验结果显示，LDA-1B在接触密集、灵巧和长时序任务上分别比现有方法提升21%、48%和23%，且能利用30%的低质量轨迹提升10%性能。|He Wang Team|[2602.12215](http://arxiv.org/abs/2602.12215)|**[link](https://pku-epic.github.io/LDA)**|
|**2026-02-12**|**DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation**|当前基础模型在音视频生成方面取得了显著进展，但将以人为中心的任务（如参考音视频生成、视频编辑、音频驱动视频动画）视为独立目标，且难以在单一框架内实现对多角色身份和声音音色的精确、解耦控制。为此，本研究提出了DreamID-Omni，一个用于可控以人为中心音视频生成的统一框架。该框架设计了对称条件扩散Transformer来整合异构条件信号，并通过双层解耦策略（信号层面的同步RoPE和语义层面的结构化字幕）解决了多人物场景中的身份-音色绑定和说话人混淆问题。此外，多任务渐进式训练方案利用弱约束生成先验正则化强约束任务。广泛实验证明，DreamID-Omni在视频、音频和音视频一致性方面均实现了全面的最先进性能，甚至超越了领先的商业模型。|Xiangwang Hou Team|[2602.12160](http://arxiv.org/abs/2602.12160)|**[link](https://guoxu1233.github.io/DreamID-Omni/)**|
|**2026-02-12**|**It's TIME: Towards the Next Generation of Time Series Forecasting Benchmarks**|时间序列基础模型（TSFMs）正变革预测领域，但现有基准测试在数据构成、数据完整性、任务制定和分析视角上存在局限性。为解决这些问题，本研究引入了TIME，一个下一代以任务为中心的基准测试，包含50个新数据集和98个预测任务，专为严格的零样本TSFM评估设计，以避免数据泄露。通过结合大型语言模型和人类专业知识，建立了严谨的人工循环构建流程，确保高数据完整性并重新定义任务制定。此外，提出了一种新颖的模式级评估视角，超越了传统的数据集级评估，通过结构化时间序列特征来表征内在时间属性，提供对模型能力的通用洞察。研究评估了12个代表性TSFMs并建立了多粒度排行榜，以促进深入分析。|Chenghao Liu Team|[2602.12147](http://arxiv.org/abs/2602.12147)|null|
|**2026-02-12**|**Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models**|许多大学面临日益增加的财务压力，需要准确预测入学人数，但高等教育入学预测常面临数据稀疏、序列短且受报告变化和制度转变影响的问题，传统方法因此不可靠。时间序列基础模型（TSFMs）在零样本设置下，通过泄露受控的协变量构建，在年度、数据稀疏的机构预测中展现了潜力。本研究在一个零样本环境中基准测试了多种TSFM系列，并测试了一个紧凑、泄露安全的协变量集，包括从时间戳文档证据中提取的机构运营条件指数（IOCI）以及经过特征工程的Google趋势需求代理。通过严格的“扩张窗口回测”和“时间戳对齐”，结果显示协变量条件化的TSFMs在无需机构特定训练的情况下，表现与经典基准方法相当，性能差异因队列和模型而异。|Surangika Ranathunga Team|[2602.12120](http://arxiv.org/abs/2602.12120)|null|
|**2026-02-12**|**The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context**|当前的大型语言模型（LLMs）虽有强大的数据库和检索系统，但缺乏主动管理自身状态和记忆的机制，被动接受手动提供的上下文，受限于固定窗口大小。本研究引入了StateLM，一种新型基础模型，它具备内部推理循环来管理自身状态。该模型配备了一系列记忆工具（如上下文剪枝、文档索引、笔记）并被训练主动管理这些工具，从而摆脱固定窗口的架构限制。实验结果表明，StateLM在所有模型规模的长文档问答任务中持续优于标准LLMs，在聊天记忆任务中绝对准确率提升10%至20%，在深度研究任务BrowseComp-Plus上更是达到52%的准确率，远超标准LLM的5%左右。这使得LLMs从被动预测器转变为状态感知代理，实现了状态化和可管理的推理过程。|Yan Wang Team|[2602.12108](http://arxiv.org/abs/2602.12108)|null|
|**2026-02-12**|**GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning**|直接从当前观察预测多步动作块的视觉-语言-动作（VLA）模型，因场景理解和未来预测能力受限而存在不足。相比之下，预训练于网络规模视频语料库的视频世界模型具有强大的时空推理和准确的未来预测能力，为增强VLA学习提供了基础。本研究提出了GigaBrain-0.5M*，一个通过世界模型驱动强化学习训练的VLA模型，其基于在超过1万小时机器人操作数据上预训练的GigaBrain-0.5。GigaBrain-0.5M*通过RAMP（通过世界模型条件策略进行强化学习）整合强化学习，以实现鲁棒的跨任务适应。实验结果表明，RAMP相对于RECAP基线取得了显著性能提升，在“叠衣服”、“装箱”和“制作浓缩咖啡”等挑战性任务上提升了约30%，并且在真实世界部署中展示了可靠的长时序复杂操作能力。|Zheng Zhu Team|[2602.12099](http://arxiv.org/abs/2602.12099)|**[link](https://gigabrain05m.github.io/)**|
|**2026-02-12**|**Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning**|在现实世界中直接训练机器人策略成本高昂且难以扩展，而生成式仿真虽能合成大规模数据，但现有方法常难以生成逻辑连贯的长时序任务，且因开环执行难以应对动态物理不确定性。本研究提出了Affordance-Graphed Task Worlds (AGT-World)，一个统一框架，能够根据现实世界观察自主构建交互式仿真环境及相应的机器人任务策略。AGT-World通过将任务空间形式化为结构化图，实现复杂目标的精确分层分解为原子原语，并引入结合视觉-语言模型推理和几何验证的混合反馈自进化机制来自主优化策略。大量实验证明，AGT-World在成功率和泛化能力上显著优于现有方法，实现了提议、执行和纠错的自改进循环，从而促进可扩展的机器人学习。|Changshui Zhang Team|[2602.12065](http://arxiv.org/abs/2602.12065)|null|
|**2026-02-12**|**VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model**|视觉-语言-动作（VLA）模型的性能和可靠性可通过迭代在线交互提升，但现实世界策略回放数据收集昂贵。虽然学习到的模拟器（动作条件视频生成模型）有望生成额外回放数据，但现有世界模型缺乏物理保真度，难以精确建模接触密集物体操纵中的关键物理细节。本研究提出一种简单的迭代改进算法，利用真实世界回放数据提升世界模型的保真度，然后该世界模型再用于生成补充合成数据以改进VLA模型。在真实机器人实验中，该方法显著提升了最先进VLA模型在多个下游任务上的性能，相比基础策略，成功率绝对提升39.2%，相比使用生成合成回放数据进行训练，提升了11.6%。|Chelsea Finn Team|[2602.12063](http://arxiv.org/abs/2602.12063)|null|
|**2026-02-12**|**HoloBrain-0 Technical Report**|基础模型研究与可靠的真实世界机器人部署之间存在差距。为弥合此差距，本研究引入了HoloBrain-0，一个全面的视觉-语言-动作（VLA）框架。其核心是一个新颖的VLA架构，明确融入了机器人具身先验（如多视角相机参数和运动学描述），以增强3D空间推理并支持多样化的具身形态。该设计通过可扩展的“预训练-后训练”范式进行验证，在RoboTwin 2.0、LIBERO和GenieSim等仿真基准测试中取得了最先进的结果，并在具有挑战性的长时序真实世界操作任务中表现出色。值得一提的是，其高效的0.2B参数变体能与更大的基线模型相媲美，支持低延迟的设备端部署。为加速研究，HoloBrain生态系统已完全开源，包括预训练VLA基础模型、后训练检查点和全栈VLA基础设施RoboOrchard。|Zhizhong Su Team|[2602.12062](http://arxiv.org/abs/2602.12062)|null|
|**2026-02-12**|**FedGRPO: Privately Optimizing Foundation Models with Group-Relative Rewards from Domain Client**|针对联邦基础模型(FedFMs)中现有知识迁移方法存在的训练成本高、通信开销大及隐私风险问题，本研究将其重构为强化学习式评估过程。提出了FedGRPO框架，通过构建轻量级置信图进行能力专家选择，并利用"组相对"概念将问题与解决方案打包为候选策略，仅聚合客户端返回的标量奖励信号，而非直接交换数据或模型更新。实验结果表明，FedGRPO在保证隐私和降低通信开销的同时，实现了优于传统FedFMs基线的下游任务精度和通信效率。|Yuxing Han Team|[2602.12014](http://arxiv.org/abs/2602.12014)|null|
|**2026-02-12**|**Accelerating Robotic Reinforcement Learning with Agent Guidance**|强化学习(RL)在机器人操作技能学习中面临样本效率低下，而现有的人在环(HIL)方法受限于可扩展性与人类监督的低效性。本研究提出了Agent-guided Policy Search (AGPS)框架，用多模态智能体取代人类监督者，将智能体视为语义世界模型，注入内在价值先验来指导物理探索。通过可执行工具，智能体提供精确的纠正航点和空间约束来修剪探索。实验结果表明，AGPS在精细插入和变形物体操作任务中，样本效率优于HIL方法，从而实现了自动化监督，为可扩展的机器人学习提供了新途径。|Yaodong Yang Team|[2602.11978](http://arxiv.org/abs/2602.11978)|null|
|**2026-02-12**|**Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning**|为实现高效空间推理，本研究探讨了低比特规划行为在有限精度预算下，是否主要由总比特位宽决定，或由比特位在模型模块间的分配方式决定。通过在DINO-WM上进行混合位评估，观察到8比特和6比特设置接近FP16，3比特设置性能崩溃，而4比特设置对位宽分配敏感。在4比特过渡区，保留编码器精度可提升规划性能。这些发现表明，模块感知、预算感知的量化策略对于高效空间推理具有重要研究意义。|Vaishak Menon Team|[2602.11882](http://arxiv.org/abs/2602.11882)|null|
|**2026-02-12**|**PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts**|潜在扩散模型(LDMs)在 <=0.25° 的高分辨率集合天气预报中存在扩散性受限问题，且现有频率方法因缺乏对变量间频谱异质性的考虑而导致正则化强度不均。本研究提出了PuYun-LDM模型，结合3D掩码自编码器(3D-MAE)编码天气状态演化特征作为扩散模型的额外条件，并采用变量感知掩码频率建模(VA-MFM)策略自适应选择阈值。实验证明，PuYun-LDM增强了潜在扩散性，在短时效预报中表现优于ENS，长时效预报中与ENS相当，并能在短时间内高效生成全球预报。|Bin Wang Team|[2602.11807](http://arxiv.org/abs/2602.11807)|null|
|**2026-02-12**|**HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model**|类人机器人在处理非结构化环境中复杂全身任务时，现有方法难以应对具有独立动力学和非完整约束的欠驱动物体，且缺乏外部状态估计。本研究提出了HAIC统一框架，通过仅利用本体感受历史数据估计高阶物体状态的动力学预测器，并将预测投影至静态几何先验形成空间接地动态占用图，使策略能在盲区推断碰撞边界和接触可供性。通过非对称微调，世界模型持续适应学生策略。实验表明，HAIC在敏捷任务和多物体长时序任务中均取得了高成功率，有效应对惯性扰动并预测多物体动力学。|Renjing Xu Team|[2602.11758](http://arxiv.org/abs/2602.11758)|**[link](https://haic-humanoid.github.io/)**|
|**2026-02-12**|**ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation**|具身导航领域长期受限于任务特定的架构。本研究引入了ABot-N0，一个统一的视觉-语言-动作(VLA)基础模型，旨在实现点目标、物体目标、指令跟随、POI目标和人物跟随五项核心导航任务的“大一统”。模型采用分层“大脑-行动”架构，将基于大型语言模型的认知大脑与基于流匹配的动作专家结合。为支持大规模学习，研究团队开发了ABot-N0数据引擎， curating 16.9M专家轨迹和5.0M推理样本。ABot-N0在7个基准测试中取得了新的SOTA性能，并整合规划器与分层拓扑记忆，实现动态真实世界环境中的鲁棒长时序任务。|Mu Xu Team|[2602.11598](http://arxiv.org/abs/2602.11598)|**[link](https://amap-cvlab.github.io/ABot-Navigation/ABot-N0/)**|
|**2026-02-12**|**Brain4FMs: A Benchmark of Foundation Models for Electrical Brain Signal**|脑基础模型(BFMs)在神经科学领域快速发展，但缺乏统一的方法理解和标准化评估框架。本研究旨在填补这一空白，通过自监督学习(SSL)分类法组织BFMs，并从数据集角度总结常见下游任务，整理临床和以人为中心神经技术应用的代表性公共数据集。在此基础上，推出了Brain4FMs开放评估平台，集成了15个代表性BFM和18个公共数据集。该平台支持标准化比较和分析预训练数据、SSL策略和架构对泛化和下游性能的影响，以指导更准确、可迁移的BFMs开发。|Yang Yang Team|[2602.11558](http://arxiv.org/abs/2602.11558)|null|
|**2026-02-12**|**TS-Memory: Plug-and-Play Memory for Time Series Foundation Models**|时间序列基础模型(TSFMs)在分布偏移下的下游领域适应面临挑战，现有参数化适应易导致灾难性遗忘，而非参数化检索则引入高推理延迟。本研究提出了参数化记忆蒸馏方法并实现为TS-Memory，一个轻量级记忆适配器。TS-Memory分两阶段训练：首先构建离线、无信息泄露的kNN教师模型合成置信度感知的量化目标；其次通过置信度门控监督将检索诱导的分布校正蒸馏到记忆适配器中。实验表明，TS-Memory在多种TSFMs和基准测试上持续改进点预测和概率预测性能，且效率与冻结骨干网络相当，实现了无检索部署。|Yuxuan Liang Team|[2602.11550](http://arxiv.org/abs/2602.11550)|null|
|**2026-02-12**|**Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use**|在预算约束下，大型语言模型调用外部工具解决多步骤任务的工具增强型智能体面临巨大状态-动作空间、高结果方差和过高探索成本导致直接规划难以处理的问题。本研究提出了INTENT，一个推理时规划框架，利用意图感知的层次世界模型来预测未来的工具使用和风险校准成本，并在线指导决策。实验证明，INTENT在成本增强型StableToolBench上严格遵循硬预算可行性，显著提高了任务成功率，并在工具价格和预算动态变化下表现出鲁棒性。|Qi Qi Team|[2602.11541](http://arxiv.org/abs/2602.11541)|null|
|**2026-02-12**|**Vascular anatomy-aware self-supervised pre-training for X-ray angiogram analysis**|X射线血管造影图像分析受限于带标注数据稀缺，大规模自监督学习(SSL)在该领域潜力未被充分挖掘。本研究引入了VasoMIM框架，通过解剖引导的掩码策略强制模型学习血管语义，并利用解剖一致性损失保留血管结构一致性，从而增强学习表征的判别力。同时，策展了迄今最大的X射线血管造影预训练数据集XA-170K。VasoMIM在多个下游任务中展现出卓越的可迁移性和领先的性能，凸显了其作为X射线血管造影分析基础模型的巨大潜力。|Zeng-Guang Hou Team|[2602.11536](http://arxiv.org/abs/2602.11536)|null|

<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>

## VLM

|Publish Date|Title|Chinese Summary|Authors|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-12**|**Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment**|为解决通用机器人中视觉-语言-动作（VLA）模型存在的“意图-动作差距”问题，即生成动作与指令不一致的现象，本研究提出了一种测试时验证方法。该方法通过联合扩展复述指令和生成动作数量来提高测试时样本多样性，并引入了CoVer对比验证器和分层验证推理管线。实验结果表明，与仅扩展策略预训练相比，该验证方法在SIMPLER基准上分布内性能提升22%，分布外提升13%，真实世界实验提升45%，在PolaRiS基准上任务进度提升14%，成功率提升9%。|Marco Pavone Team|[2602.12281](http://arxiv.org/abs/2602.12281)|null|
|**2026-02-12**|**ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images**|针对现有视觉语言模型（VLM）在企业文档结构化信息提取（IE）方面，对多样文档类型和灵活模式的全面细粒度提取能力研究不足，以及现有数据集存在局限性的问题，本研究引入了ExStrucTiny，一个统一了关键实体提取（KEE）、关系提取（RE）和视觉问答（VQA）方面的新型结构化IE基准数据集。该数据集通过结合人工和合成样本的新颖流程构建，涵盖更广泛的文档类型和提取场景。通过对开放和闭源VLM在此基准上的分析，揭示了模式适应、查询规范不足和答案定位等挑战，旨在为文档结构化IE的通用模型改进提供基础。|Manuela Veloso Team|[2602.12203](http://arxiv.org/abs/2602.12203)|null|
|**2026-02-12**|**3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting**|针对现有零样本对象导航（ZSON）方法依赖场景抽象导致高级决策受限于低级感知准确性的问题，本研究提出了3DGSNav框架。该框架将3D Gaussian Splatting (3DGS) 作为视觉语言模型（VLM）的持久记忆，通过主动感知逐步构建环境的3DGS表示，以增强空间推理并实现轨迹引导的自由视点渲染。此外，通过结构化视觉提示和思维链（CoT）提示进一步改善VLM推理，并在导航时结合实时目标检测和VLM驱动的主动视点切换进行目标重验证。实验结果表明，该方法在多个基准和真实机器人实验中均展现出稳健且具竞争力的性能。|Xinyi Yu Team|[2602.12159](http://arxiv.org/abs/2602.12159)|null|
|**2026-02-12**|**Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning**|鉴于在真实世界中训练机器人策略成本高昂且现有生成模拟难以生成逻辑连贯的长周期任务并处理动态物理不确定性，本研究提出了Affordance-Graphed Task Worlds (AGT-World) 统一框架。该框架基于真实世界观测自主构建交互式模拟环境和机器人任务策略，通过将任务空间形式化为结构化图，实现复杂目标的精确分层分解，并引入了结合VLM推理和几何验证的自演化机制来优化策略。实验结果表明，该方法在成功率和泛化能力上显著优于现有方法，实现了提议、执行和修正的自我改进循环，以支持可扩展的机器人学习。|Changshui Zhang Team|[2602.12065](http://arxiv.org/abs/2602.12065)|null|
|**2026-02-12**|**Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation**|鉴于新生儿复苏活动准确记录的重要性及其在实践中的不足，以及现有方法在识别细粒度活动上的挑战，本研究探索了生成式AI（GenAI）方法，特别是结合大型语言模型（LLM）的局部视觉-语言模型（VLM），以改进新生儿复苏视频中的活动识别。研究将几种零样本VLM策略和微调VLM（包括LoRA）与分类头进行评估，并与监督式TimeSFormer基线进行比较。结果表明，小型VLM虽然容易产生幻觉，但经过LoRA微调后，F1分数可达0.91，显著超越TimeSFormer的0.70。|Øyvind Meinich-Bache Team|[2602.12002](http://arxiv.org/abs/2602.12002)|null|
|**2026-02-12**|**Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion**|针对PDF到Markdown转换作为RAG管道关键步骤，以及现有基准多侧重英文或中文并可能过度惩罚无关格式差异的问题，本研究引入了一个专门针对法语文档、通过模型不一致采样挑选的挑战性新基准。该基准涵盖手写表格、复杂布局、密集表格和富含图形的页面，并采用单元测试式检查和类别特定归一化进行评估，以减少无关的呈现差异。实验结果显示，在15个模型中，最强的专有模型在手写和表格处理上表现出更高的鲁棒性，同时一些开源系统在标准打印布局上仍具竞争力。|Nicolas Mery Team|[2602.11960](http://arxiv.org/abs/2602.11960)|null|
|**2026-02-12**|**Are Two LLMs Better Than One? A Student-Teacher Dual-Head LLMs Architecture for Pharmaceutical Content Optimization**|针对大型语言模型（LLM）在制药等受监管领域内容创作中面临的科学准确性和合规性挑战，以及手动质量控制（QC）低效易错的问题，本研究引入了LRBTC，一个模块化的LLM和VLM驱动的QC架构。该架构涵盖语言、法规、品牌、技术和内容结构检查，并结合了师生双模型架构、人工干预（HITL）工作流和瀑布式规则过滤机制。实验结果表明，LRBTC在AIReg-Bench上取得了83.0%的F1和97.5%的召回率，相比Gemini 2.5 Pro，遗漏违规减少5倍；在CSpelling上平均准确率提高26.7%。误差分析揭示当前模型擅长检测拼写错误，但在复杂医学语法和标点错误识别方面仍有提升空间。|Anubhav Girdhar Team|[2602.11957](http://arxiv.org/abs/2602.11957)|null|
|**2026-02-12**|**LAMP: Implicit Language Map for Robot Navigation**|为解决现有视觉-语言模型（VLM）零样本导航方法在大环境中因显式存储语言向量而导致的内存需求过高和细粒度规划分辨率有限的问题，本研究提出了LAMP（Language Map）框架。该框架通过学习连续的、语言驱动的隐式神经语言场来编码语言特征，并结合稀疏图实现高效的粗略路径规划，进而通过梯度优化在学习场中细化目标姿态。该方法还采用贝叶斯框架建模嵌入不确定性以增强泛化能力，并通过图采样策略扩展到大环境。实验证明，LAMP在内存效率和细粒度目标到达精度方面均优于现有显式方法。|Sunwook Choi Team|[2602.11862](http://arxiv.org/abs/2602.11862)|**[link](https://lab-of-ai-and-robotics.github.io/LAMP/)**|
|**2026-02-12**|**JEPA-VLA: Video Predictive Embedding is Needed for VLA Models**|针对现有视觉-语言-动作（VLA）模型在机器人操作中存在的样本效率低和泛化能力有限的问题，本研究认为这与被忽视的预训练视觉表征在环境理解和策略先验方面知识不足有关。研究发现，视频上预训练的预测嵌入（特别是V-JEPA 2）能有效捕捉任务相关的时态动态并过滤不可预测的环境因素，从而弥补现有视觉表征的不足。基于此，论文提出了JEPA-VLA，一种将预测嵌入自适应集成到现有VLA中的简单而有效的方法。实验结果表明，JEPA-VLA在一系列基准和真实机器人任务中均取得了显著的性能提升。|Mingsheng Long Team|[2602.11832](http://arxiv.org/abs/2602.11832)|null|
|**2026-02-12**|**Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models**|为解决大型视觉-语言模型（LVLMs）普遍存在的物体幻觉问题，该问题源于视觉特征和预训练文本表示在网络深层中的纠缠，本研究提出了REVIS，一个无需训练的框架。REVIS基于潜在空间几何原理，通过正交投影精确提取纯视觉信息向量，并采用校准策略，仅在视觉信息被抑制的精确深度进行稀疏干预，从而有效恢复视觉信息。经验评估结果显示，REVIS与最先进的基线相比，将目标幻觉率降低了约19%，同时保持了模型原有的通用推理能力。|Zhou Yang Team|[2602.11824](http://arxiv.org/abs/2602.11824)|null|
|**2026-02-12**|**Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation**|现有主流的视觉-语言模型测试时自适应（TTA）方法依赖香农熵（SE）衡量预测不确定性，但由于预训练数据偏差，SE会产生有偏的不确定性估计。为解决此问题，研究发现并证明Tsallis熵（TE）通过引入非广延参数q，天然适合表征有偏分布。在此基础上，本文提出了自适应去偏Tsallis熵（ADTE），为每个类别定制类特定的q^l参数，该参数通过对持续传入的测试实例估计标签偏差进行归一化得到。实验结果表明，ADTE在ImageNet及其五种变体上超越了最先进的方法，并在10个跨域基准测试中取得了最高的平均性能，证实了其有效性。|Jianfeng Lu Team|[2602.11743](http://arxiv.org/abs/2602.11743)|null|
|**2026-02-12**|**Adapting Vision-Language Models for E-commerce Understanding at Scale**|电商产品理解需要文本、图像和结构化属性等多模态的强大理解能力。通用视觉-语言模型（VLMs）虽能提供泛化能力，但如何将其有效地适应电商数据中以属性为中心、多图像和噪声多的特性，同时不牺牲通用性能，是一个未被充分探索的问题。本文通过大规模实验研究，展示了对通用VLM进行有针对性的适配，可以在大幅提升电商任务性能的同时，保持其广泛的多模态能力。此外，本文还提出了一个新颖且全面的评估套件，涵盖了深度产品理解、严格指令遵循和动态属性提取等任务。|Shahram Khadivi Team|[2602.11733](http://arxiv.org/abs/2602.11733)|null|
|**2026-02-12**|**STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning**|在视觉-语言模型（VLMs）中，文本描述与视觉坐标之间的不匹配常导致幻觉问题，在时空视频定位（STVG）等密集预测任务中尤为突出。现有方法通常增强视觉-文本对齐或添加辅助解码器，但这会引入额外的可训练模块，导致高昂的标注和计算成本。本文提出了一种新颖的视觉提示范式，通过将每帧坐标预测重新表述为实例级识别问题，为每个对象分配唯一且时间一致的ID，并将其嵌入视频作为视觉提示。此外，研究引入了STVG-R1，这是首个用于STVG的强化学习框架，通过任务驱动奖励联合优化时间精度、空间一致性和结构化格式正则化。实验结果表明，STVG-R1在六个基准测试中表现出色，在HCSTVG-v2上m_IoU比基线Qwen2.5-VL-7B高出20.9%，达到SOTA，并展现出强大的零样本泛化能力。|Qing Li Team|[2602.11730](http://arxiv.org/abs/2602.11730)|null|
|**2026-02-12**|**ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning**|大规模视觉指令微调（VIT）是提升视觉-语言模型（VLMs）在多模态任务中性能的关键范式，但其在大型数据集上的训练因数据冗余而计算昂贵且低效。现有的数据选择方法要么需要昂贵的训练或梯度计算，要么依赖代理模型或指令无关表示且复杂度高，限制了可扩展性。本文提出了ScalSelect，一种可扩展的无训练多模态数据选择方法，其复杂度与样本数量呈线性关系，无需外部模型或辅助数据集。ScalSelect通过提取指令令牌在目标VLM中最受关注的视觉特征来构建样本表示，然后识别其表示最能近似整个数据集主导子空间的样本，从而实现无需成对比较的可扩展重要性评分。广泛的实验表明，ScalSelect仅使用16%的数据即可达到全数据集训练97.5%以上的性能，在某些设置下甚至超越了全数据训练。|Kai Chen Team|[2602.11636](http://arxiv.org/abs/2602.11636)|**[link](https://github.com/ChangtiWu/ScalSelect}{ScalSelect})**|
|**2026-02-12**|**SkillRater: Untangling Capabilities in Multimodal Data**|传统数据筛选方法通常只给样本分配一个单一的质量分数，但这在模型需要学习多种不同能力时显得局限。本文认为质量应是多维的，每个维度对应模型需掌握的一种能力。为此，我们提出了SkillRater框架，将数据过滤分解为多个专业的评估器，每个评估器负责一种能力，并通过元学习在独立验证目标上进行训练。这些评估器的分数通过渐进式选择规则组合：在每个训练阶段，只要任一评估器将样本排名高于随时间收紧的阈值，该样本即被保留，以在早期保持多样性，后期聚焦高价值样本。在视觉语言模型上的验证表明，SkillRater在视觉理解、OCR和STEM推理能力上均显著优于未过滤基线，且学习到的评估器信号几乎正交，证实了多维度分解的有效性。|Akshat Shrivastava Team|[2602.11615](http://arxiv.org/abs/2602.11615)|null|
|**2026-02-12**|**Chatting with Images for Introspective Visual Thinking**|当前大型视觉-语言模型（LVLMs）通常依赖基于单次视觉编码的纯文本推理，这常导致细粒度视觉信息丢失，尤其是在处理跨区域或多图像的视觉语义或几何关系推理时。为解决这些挑战，本文提出了“与图像对话”这一新框架，将视觉操作重新定义为语言引导的特征调制。在该框架下，模型在富有表现力的语言提示指导下，动态地对多个图像区域进行联合再编码，从而实现语言推理与视觉状态更新之间更紧密的耦合。我们通过ViLaVT实例化了这一范式，它是一个配备动态视觉编码器的新型LVLM，并采用两阶段课程（监督微调和强化学习）进行训练。广泛的实验表明，ViLaVT在八个基准测试中取得了显著且一致的改进，尤其在复杂的多图像和基于视频的空间推理任务上表现突出。|Tieniu Tan Team|[2602.11073](http://arxiv.org/abs/2602.11073)|null|
|**2026-02-11**|**Hierarchical Concept Embedding & Pursuit for Interpretable Image Classification**|可解释设计模型在计算机视觉中日益受到关注，因为它们能为其预测提供忠实的解释。在图像分类中，这类模型通常从图像中提取人类可解释的概念并用于分类。稀疏概念恢复方法利用视觉-语言模型的潜在空间将图像嵌入表示为概念嵌入的稀疏组合，但这类方法忽视了概念的层次结构，可能导致预测正确但解释与层次结构不一致。为解决此问题，本文提出了分层概念嵌入与追踪（HCEP）框架，它在潜在空间中诱导概念嵌入的层次结构，并利用分层稀疏编码来恢复图像中存在的概念。实验结果表明，HCEP在概念精度和召回率上均优于基线，同时保持了有竞争力的分类准确率，并且在样本数量有限时展现出卓越的分类和概念恢复性能，证明了将层次结构融入稀疏编码能产生更可靠和可解释的图像分类模型。|René Vidal Team|[2602.11448](http://arxiv.org/abs/2602.11448)|null|
|**2026-02-11**|**Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling**|扩散模型和流匹配模型的偏好优化需要既具有判别鲁棒性又计算高效的奖励函数。视觉-语言模型（VLMs）已成为主要的奖励提供者，利用其丰富的多模态先验来指导对齐。然而，它们的计算和内存成本很高，并且通过像素空间奖励优化潜在扩散生成器会引入域不匹配，使对齐复杂化。本文提出了DiNa-LRM，一种扩散原生的潜在奖励模型，它直接在噪声扩散状态上构建偏好学习。DiNa-LRM引入了一种噪声校准的Thurstone似然，其不确定性依赖于扩散噪声，并利用预训练的潜在扩散骨干网络与时间步条件奖励头。实验结果显示，DiNa-LRM在图像对齐基准测试中显著优于现有基于扩散的奖励基线，并以极低的计算成本实现了与最先进VLM相当的性能，显著改善了偏好优化动态，实现了更快、更资源高效的模型对齐。|Wenhan Luo Team|[2602.11146](http://arxiv.org/abs/2602.11146)|**[link](https://github.com/HKUST-C4G/diffusion-rm)**|
|**2026-02-11**|**Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration**|自博弈已使大型语言模型（LLMs）通过自生成挑战实现自主提升。然而，现有视觉-语言模型（VLMs）的自博弈方法依赖与静态图像集的被动交互，导致对初始数据集的强依赖和学习效率低下。为解决这些局限性，本文提出了Active-Zero框架，将模型学习从被动交互转向主动探索视觉环境。Active-Zero采用三个共同进化的智能体：一个Searcher根据模型能力前沿从开放世界存储库检索图像；一个Questioner合成校准的推理任务；一个Solver通过准确性奖励进行优化。这种闭环机制实现了自我脚手架的自动课程学习。在Qwen2.5-VL-7B-Instruct的12个基准测试中，Active-Zero在推理任务上平均准确率达到53.97%（提升5.7%），在通用理解上达到59.77%（提升3.9%），持续优于现有自博弈基线，表明主动探索是可扩展和自适应自进化视觉-语言系统的关键要素。|Tat-Seng Chua Team|[2602.11241](http://arxiv.org/abs/2602.11241)|null|
|**2026-02-11**|**Safe mobility support system using crowd mapping and avoidance route planning using VLM**|自主移动机器人在动态、尤其是拥挤环境中安全有效导航仍面临挑战。本文提出了一种新颖的框架，该框架集成了视觉-语言模型（VLM）和高斯过程回归（GPR），用于生成动态人群密度图（“抽象图”），以实现自主机器人导航。我们的方法利用VLM识别抽象环境概念（如人群密度）的能力，并通过GPR以概率方式表示这些概念。在大学校园进行的真实世界试验结果表明，机器人成功地生成了避开静态障碍物和动态人群的路径，从而增强了导航的安全性和适应性。|Koichi Ozaki Team|[2602.10910](http://arxiv.org/abs/2602.10910)|null|

<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>

## VLA

|Publish Date|Title|Chinese Summary|Authors|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-12**|**Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment**|通用机器人理解和执行自然语言指令时，VLA模型常出现“意图-动作差距”。为解决此问题，本研究提出测试时验证方法，通过联合扩展复述指令和生成动作来提高样本多样性。具体引入了CoVer，一个对比验证器，并结合“启动时计算”与分层验证推理流程，在部署时预计算多样指令并生成动作候选，然后通过验证器选择最优方案。实验结果表明，该方法在SIMPLER基准上分布内和分布外性能分别提升22%和13%，真实世界实验提升45%，并在PolaRiS基准上任务进度和成功率分别提升14%和9%。|Marco Pavone Team|[2602.12281](http://arxiv.org/abs/2602.12281)|null|
|**2026-02-12**|**GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning**|现有VLA模型因场景理解和未来预测能力受限，难以直接预测多步动作。为克服这些局限，本研究提出GigaBrain-0.5M*，一个通过世界模型强化学习训练的VLA模型。该模型基于在大量机器人操作数据上预训练的GigaBrain-0.5，并通过RAMP框架整合了世界模型强化学习，以增强跨任务适应性。实验结果显示，RAMP在RECAP基线上实现了约30%的显著性能提升，并在洗衣、打包和咖啡制作等复杂任务中展现了可靠的长期执行能力。|Zheng Zhu Team|[2602.12099](http://arxiv.org/abs/2602.12099)|**[link](https://gigabrain05m.github.io/)**|
|**2026-02-12**|**VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model**|提升VLA模型性能和可靠性面临真实世界数据收集昂贵和现有世界模型物理保真度不足的挑战。本研究提出一种迭代改进算法，利用真实世界的rollout数据提升世界模型的准确性，进而生成补充合成数据以改进VLA模型。在真实机器人上的实验表明，此方法使最先进的VLA模型在多个任务上成功率绝对提升39.2%，其中仅通过合成rollout训练就带来了11.6%的改进。|Chelsea Finn Team|[2602.12063](http://arxiv.org/abs/2602.12063)|null|
|**2026-02-12**|**HoloBrain-0 Technical Report**|为弥合基础模型研究与可靠机器人部署之间的差距，本研究推出了HoloBrain-0，一个全面的视觉-语言-动作（VLA）框架。其核心是一个新颖的VLA架构，通过显式融入机器人具身先验（如多视角相机参数和运动学描述），增强了3D空间推理能力并支持多样具身。该框架采用“预训练后微调”范式，并在多个模拟和真实世界任务中取得了最先进的性能。同时，该项目完全开源了HoloBrain生态系统，包括预训练VLA基础、微调检查点和RoboOrchard基础设施，以促进研究和实际应用。|Zhizhong Su Team|[2602.12062](http://arxiv.org/abs/2602.12062)|null|
|**2026-02-12**|**When would Vision-Proprioception Policies Fail in Robotic Manipulation?**|机器人操作中，本体感受信息对精确控制至关重要，但视觉-本体感受策略的泛化性在运动过渡阶段表现不佳。本研究发现，训练时策略倾向于利用简洁的本体感受信号，从而抑制了视觉模态的学习。为解决此问题，我们提出带阶段指导的梯度调整（GAP）算法，该算法根据本体感受估计的运动过渡概率，自适应地调节本体感受梯度的幅度，从而促进视觉模态的学习。实验证明，GAP在模拟和真实世界环境中，以及不同机器人设置和模型类型中均能提升视觉-本体感受策略的鲁棒性和泛化性。|Di Hu Team|[2602.12032](http://arxiv.org/abs/2602.12032)|null|
|**2026-02-12**|**JEPA-VLA: Video Predictive Embedding is Needed for VLA Models**|现有VLA模型尽管基于预训练VLM，但在样本效率和泛化能力上仍有局限，这与被忽视的预训练视觉表示不足以提供环境理解和策略先验有关。本研究深入分析发现，传统的视觉表示在捕捉任务相关环境信息和诱导有效策略先验方面存在不足。相比之下，本研究发现视频上预训练的预测嵌入（特别是V-JEPA 2）能有效编码任务相关的时序动态。基于此，我们提出JEPA-VLA，一种将预测嵌入自适应集成到现有VLA的简单方法。实验表明，JEPA-VLA在LIBERO、LIBERO-plus、RoboTwin2.0和真实机器人任务等一系列基准上取得了显著性能提升。|Mingsheng Long Team|[2602.11832](http://arxiv.org/abs/2602.11832)|null|
|**2026-02-12**|**ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation**|具身导航长期以来因任务特定架构而碎片化。本研究引入ABot-N0，一个统一的视觉-语言-动作（VLA）基础模型，它在点目标、物体目标、指令跟随、POI目标和人员跟随等5个核心任务上实现了“大统一”。ABot-N0采用分层“大脑-动作”架构，结合基于LLM的认知大脑进行语义推理和基于流匹配的动作专家进行精确连续轨迹生成。通过ABot-N0数据引擎构建大规模数据集支持学习。实验结果表明，ABot-N0在7个基准上实现了新的SOTA性能，显著优于专用模型，其Agentic导航系统能在动态真实世界环境中实现鲁棒的长期任务。|Mu Xu Team|[2602.11598](http://arxiv.org/abs/2602.11598)|**[link](https://amap-cvlab.github.io/ABot-Navigation/ABot-N0/)**|
|**2026-02-12**|**Scaling World Model for Hierarchical Manipulation Policies**|VLA模型在分布外（OOD）设置中表现脆弱，尤其是在有限的真实机器人数据下泛化能力不足。为解决这一泛化瓶颈，本研究引入了一个分层视觉-语言-动作框架VISTA，该框架利用大规模预训练世界模型的泛化能力进行鲁棒且可泛化的视觉子目标任务分解。VISTA包含一个作为高层规划器的世界模型和一个作为低层执行器的VLA。高层世界模型将操作任务分解为带有目标图像的子任务序列，低层策略则遵循文本和视觉指导生成动作序列。实验证明，这些合成的目标图像为低层策略提供了视觉和物理上的详细指导，使得VLA在OOD场景下的性能显著提升，从14%提高到69%，并显著优于现有基线。|Xinghang Li Team|[2602.10983](http://arxiv.org/abs/2602.10983)|null|
|**2026-02-11**|**H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model**|世界模型在机器人规划和控制中日益重要，但现有方法常难以直接与机器人动作关联，并在长周期任务中存在累积误差。本研究提出分层世界模型（H-WM），在一个统一的双层框架内联合预测逻辑和视觉状态转换，解决了传统符号世界模型与视觉感知分离的问题。H-WM结合了高层逻辑世界模型和低层视觉世界模型，将符号推理的鲁棒性与视觉观测的感知接地相结合。为训练H-WM，我们引入了一个新的机器人数据集。实验证明，分层输出为长周期任务提供了稳定一致的中间指导，减轻了误差累积，并在VLA控制策略中展现了有效性和通用性。|Yingxue Zhang Team|[2602.11291](http://arxiv.org/abs/2602.11291)|null|
|**2026-02-11**|**RISE: Self-Improving Robot Policy with Compositional World Model**|尽管VLA模型容量和数据不断扩展，但在接触密集和动态操作任务中仍易失败，在线强化学习也受限于安全和成本。为解决此问题，本研究提出RISE，一个通过想象进行机器人强化学习的可扩展框架。其核心是一个组合式世界模型，该模型通过可控动力学模型预测多视角未来，并利用进度价值模型评估想象结果，为策略改进提供信息。这些组件集成到闭环自改进管道中，在想象空间中持续生成rollout、估计优势并更新策略，无需昂贵的物理交互。实验表明，RISE在三项真实世界任务中取得了显著改进，例如在动态砖块分类中性能提升超过35%，背包打包中45%，箱子关闭中35%。|Hongyang Li Team|[2602.11075](http://arxiv.org/abs/2602.11075)|**[link](https://opendrivelab.com/kai0-rl/)**|
|**2026-02-11**|**RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation**|当前VLA模型评估主要局限于模拟环境，导致真实世界泛化能力不足。为此，本文指出现有基准在模拟真实动态、测试空间-物理智能及全自主评估方面的不足。为弥补这些缺陷，作者提出了RADAR基准，该基准包含一套物理动力学、专门的空间推理任务和基于3D指标的全自主评估流程。实验结果表明，RADAR揭示了SOTA VLA模型在适度物理动态下性能急剧下降且空间推理能力有限的脆弱性，证实了其作为VLA模型真实世界评估基准的必要性。|Guangrun Wang Team|[2602.10980](http://arxiv.org/abs/2602.10980)|null|
|**2026-02-11**|**From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving**|VLA驾驶将语言功能引入端到端规划，但其核心变化除准确性-成本权衡外尚不明确。本文通过RecogDrive进行3-RQ分析，比较VLM和纯视觉骨干网络在相同规划器下的表现。研究发现VLM能引入独特子空间，导致在长尾场景下行为差异，VLM更激进而ViT更保守。基于此，本文提出HybridDriveVLA，通过学习评分器融合两者的轨迹，将PDMS提升至92.10。进一步，DualDriveVLA实现了快慢策略，仅在低置信度时调用VLM，在15%场景中调用VLM即可达到91.00 PDMS，并使吞吐量提高3.2倍。|Yan Wang Team|[2602.10719](http://arxiv.org/abs/2602.10719)|null|
|**2026-02-11**|**Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation**|机器人操作需要预测环境对动作的响应，但现有系统常缺乏此能力，导致效率低下。鉴于VLMs无法明确预测未来状态且现有世界模型存在预测短期或空间不一致帧的问题，本文提出了一种快速且预测性的视频条件动作框架。该方法首先适配鲁棒的视频生成模型以确保未来预测的可靠性，接着通过对抗蒸馏实现快速视频生成，最后训练一个动作模型利用生成视频和真实观测纠正空间错误。实验结果表明，该方法生成的视频预测在时间连贯性和空间准确性方面表现优异，显著提升了具身一致性、空间指代能力和任务完成度。|Yanwei Fu Team|[2602.10717](http://arxiv.org/abs/2602.10717)|null|
|**2026-02-11**|**AugVLA-3D: Depth-Driven Feature Augmentation for Vision-Language-Action Models**|当前VLA模型主要依赖2D图像训练，限制了其在复杂3D环境中的空间理解和动作落地。为解决此问题，本文提出了一个将深度估计集成到VLA模型中的新框架，以丰富3D特征表示。该方法利用VGGT从RGB输入中提取3D几何线索，并引入“动作助手”模块，通过动作先验约束3D表示以确保与下游控制任务的一致性。实验结果表明，所提出的方法不仅增强了几何模糊场景中的感知，还显著提高了动作预测准确性，强调了深度驱动数据增强对弥合2D观测与3D决策差距的潜力。|F. Richard Yu Team|[2602.10698](http://arxiv.org/abs/2602.10698)|null|
|**2026-02-11**|**Improving Medical Visual Reinforcement Fine-Tuning via Perception and Reasoning Augmentation**|强化微调（RFT）在语言模型后训练中展现潜力，但在跨模态、以视觉为中心的医学影像领域应用不足，而该领域需要强大的视觉感知和结构化推理。为此，本文提出了VRFT-Aug，一个专为医学领域设计的视觉强化微调框架。VRFT-Aug通过引入先验知识注入、感知驱动策略优化、医学知情奖励塑造和行为模仿等训练策略来增强感知和推理。实验结果表明，该方法在多个医学数据集上持续优于标准监督微调和RFT基线，并提供了可推广到其他医学图像任务的实用训练启发。|Qicheng Lao Team|[2602.10619](http://arxiv.org/abs/2602.10619)|null|
|**2026-02-11**|**LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer**|机器人学长期目标是实现零样本部署的通用策略，但现有VLA模型与训练实体紧密耦合。针对此问题，本文提出了语言-动作预训练（LAP），一种将低级机器人动作直接用自然语言表示的方法，使动作监督与预训练VLM的输入-输出分布对齐，无需定制化设计或昂贵标注。基于LAP，本文提出了LAP-3B，实现了在未见机器人上的显著零样本迁移，平均成功率超过50%，比现有VLA模型提升约2倍。此外，LAP还支持高效适应、有利扩展，并通过统一的语言-动作格式在协同训练中获得额外收益。|Anirudha Majumdar Team|[2602.10556](http://arxiv.org/abs/2602.10556)|**[link](https://lap-vla.github.io)**|
|**2026-02-11**|**Found-RL: foundation model-enhanced reinforcement learning for autonomous driving**|强化学习在自动驾驶中面临样本效率低和语义可解释性不足问题，而基础模型（特别是VLM）虽能提供丰富知识，但高推理延迟阻碍其在RL训练中的实时部署。为此，本文提出了Found-RL平台，通过异步批量推理框架将VLM推理与仿真循环解耦，解决了延迟瓶颈。该平台引入了价值边际正则化和优势加权动作指导等监督机制，将VLM建议有效提炼到RL策略中。此外，通过条件对比动作对齐解决CLIP的动态盲区问题，实现密集奖励塑造。Found-RL使得轻量级RL模型在保持实时推理（500 FPS）的同时，达到接近十亿参数VLM的性能。|Sikai Chen Team|[2602.10458](http://arxiv.org/abs/2602.10458)|null|
|**2026-02-10**|**Hardware Co-Design Scaling Laws via Roofline Modelling for On-Device LLMs**|VLA模型在资源受限设备部署中面临LLM骨干网络选择挑战，需平衡准确性与推理延迟及硬件效率。本文提出了硬件协同设计法则，将模型训练损失建模为架构超参数的函数，并通过屋脊线模型表征推理延迟，从而建立了准确性-延迟的直接对应关系。通过对1,942个候选架构进行经验评估和训练，拟合出架构与训练损失的缩放定律。将该定律与延迟建模结合，本文确定了硬件协同设计LLM的帕累托前沿，并将架构搜索公式化为精度与性能的联合优化。结果显示，该方法将架构选择时间从数月缩短到数天，并在相同延迟下，其协同设计的架构在WikiText-2上的困惑度降低了19.42%。|Cheng Deng Team|[2602.10377](http://arxiv.org/abs/2602.10377)|null|
|**2026-02-10**|**ST4VLA: Spatially Guided Training for Vision-Language-Action Models**|大型VLM虽擅长多模态理解，但在具身任务中将指令转化为低级运动动作时表现不足。为此，本文引入了ST4VLA，一个双系统VLA框架，通过空间引导训练使动作学习与VLM中的空间先验对齐。ST4VLA包含两阶段：首先是空间基础预训练，利用大规模和机器人数据通过点、框、轨迹预测为VLM注入可迁移先验；其次是空间引导动作后训练，通过空间提示促使模型生成更丰富的空间先验以指导动作生成。实验表明，ST4VLA显著提升了Google Robot和WidowX Robot的性能，在SimplerEnv上创造了SOTA，并展现出对未见物体、转述指令的更强泛化能力及在真实世界中对扰动的鲁棒性。|Jiangmiao Pang Team|[2602.10109](http://arxiv.org/abs/2602.10109)|null|
|**2026-02-10**|**EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration**|人形机器人运动-操作任务面临数据需求高和具身差距挑战。针对此，本文提出了EgoHumanoid框架，首次利用大量以自我为中心的人类演示数据与有限机器人数据共同训练视觉-语言-动作策略，使人形机器人在多样真实环境中执行运动-操作。为弥合人类与机器人间的形态和视点差异，本文引入了包含硬件设计、数据处理的系统对齐流程，并开发了便携式人类数据收集系统。其核心是视点对齐和动作对齐，分别减少视觉域差异和将人类动作映射到机器人动作空间。真实世界实验表明，整合人类演示数据显著优于仅用机器人数据的基线（51%），尤其是在未见环境中。|Li Chen Team|[2602.10106](http://arxiv.org/abs/2602.10106)|**[link](https://opendrivelab.com/EgoHumanoid)**|

<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>

## Humanoid

|Publish Date|Title|Chinese Summary|Authors|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-12**|**General Humanoid Whole-Body Control via Pretraining and Fast Adaptation**|现有通用人形机器人全身控制器在运动多样性、快速适应性和高动态场景下的鲁棒平衡方面面临挑战。为此，本文提出了FAST框架，通过引入Parseval-Guided Residual Policy Adaptation学习轻量级delta动作策略，实现对分布外运动的高效适应并减轻灾难性遗忘；同时，结合Center-of-Mass-Aware Control融入质心相关观测与目标以增强平衡性。仿真与真实世界实验表明，FAST在鲁棒性、适应效率和泛化性上均超越现有最佳基线。|Zongqing Lu Team|[2602.11929](http://arxiv.org/abs/2602.11929)|null|
|**2026-02-12**|**HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model**|人形机器人在非结构化环境中的复杂全身任务潜力巨大，但现有的人机交互方法多忽略具有独立动力学和非完整约束的欠驱动物体带来的控制难题。本文提出了HAIC统一框架，通过一个无需外部状态估计的动力学预测器，仅从本体感受历史估计高阶物体状态，并将其投影到静态几何先验以形成动态占用图，使策略能推断盲区内的碰撞和接触信息。结合不对称微调，HAIC在人形机器人上实现了对各种负载下的敏捷任务（如滑板、推拉推车）的高成功率，并能通过预测多物体动力学完成长时多物体任务（如搬运箱子）。|Renjing Xu Team|[2602.11758](http://arxiv.org/abs/2602.11758)|**[link](https://haic-humanoid.github.io/)**|
|**2026-02-12**|**Future Mining: Learning for Safety and Security**|采矿业正演变为AI驱动的物理信息系统，但恶劣环境和新兴网络物理威胁严重影响安全与运行可靠性。本文提出了一个统一智能安全与安保架构，旨在整合多模态感知、安全联邦学习、强化学习、DTN通信和能量感知传感。该架构包含矿工定位、多模态态势感知、后门攻击监控、可信联邦LFD和物联网驱动设备健康监测等五个核心模块，共同解决矿工安全、威胁理解、联邦鲁棒性和预测性维护问题。该框架为构建弹性、可信的智能采矿系统提供了全面的研究愿景。|Sanjay Madria Team|[2602.11472](http://arxiv.org/abs/2602.11472)|null|
|**2026-02-12**|**Humanoid Manipulation Interface: Humanoid Whole-Body Manipulation from Robot-Free Demonstrations**|针对当前仿人机器人全身操控方法受限于硬件物流和复杂奖励工程，导致自主技能有限的问题，本研究提出了Humanoid Manipulation Interface (HuMI)。HuMI是一个便携高效的框架，允许通过便携式硬件捕获丰富全身运动数据，实现无机器人数据收集。这些数据驱动的分层学习管道能将人类动作转化为灵巧且可行的仿人机器人技能。实验证明，HuMI在数据收集效率上比遥操作提高了3倍，并在未见过环境中实现了70%的成功率，有效解决了多样化全身操控任务的学习难题。|Yang Gao Team|[2602.06643](http://arxiv.org/abs/2602.06643)|**[link](https://humanoid-manipulation-interface.github.io)**|
|**2026-02-11**|**ExtremControl: Low-Latency Humanoid Teleoperation with Direct Extremity Control**|现有的人形机器人遥操作系统因依赖预处理的运动重定向和基于位置的PD控制，导致高延迟，限制了快速反应任务的执行。本文提出了ExtremControl低延迟全身控制框架，其核心在于直接操作选定刚性链节（尤其是末端）的SE(3)姿态以避免全身重定向，利用笛卡尔空间映射直接转换人类运动为机器人链节目标，并在底层融入速度前馈控制以支持高响应行为。实验结果表明，ExtremControl实现了端到端低至50ms的延迟，远超现有工作200ms的限制，从而使人形机器人能够进行乒乓球平衡、杂耍等需要快速反馈的动态任务。|Chuang Gan Team|[2602.11321](http://arxiv.org/abs/2602.11321)|**[link](https://owenowl.github.io/extremcontrol)**|
|**2026-02-11**|**APEX: Learning Adaptive High-Platform Traversal for Humanoid Robots**|深度强化学习虽推动了人形机器人行走能力发展，但对超出腿长的高平台穿越仍面临挑战，因现有方法常收敛于高冲击、不安全的跳跃式方案。本文提出APEX系统，通过组合地形条件行为（攀爬、行走、站立/躺下）实现感知性的基于攀爬的高平台穿越。核心在于引入广义棘轮进度奖励，为学习接触密集型、目标导向的机动提供密集且无速度的监督，同时通过建模仿真映射伪影和部署时滤波提升感知。实验证明，该系统在Unitree G1人形机器人上实现了0.8米平台（腿长114%）的零样本sim-to-real穿越，并展现出对平台高度和初始姿态的鲁棒适应性及多技能平稳切换能力。|Ding Zhao Team|[2602.11143](http://arxiv.org/abs/2602.11143)|**[link](https://apex-humanoid.github.io/)**|
|**2026-02-11**|**Towards Learning a Generalizable 3D Scene Representation from 2D Observations**|现有神经辐射场方法多在相机坐标系下操作，难以直接应用于机器人操作中的3D工作空间占用预测。本文提出了一种可泛化的神经辐射场方法，能从机器人自我中心观测预测3D工作空间占用率。该模型在全球工作空间框架中构建占用表示，并能集成灵活的源视图以泛化到未见物体排列，无需场景特定微调。在人形机器人上的实验表明，该模型在40个真实场景训练后，实现了26mm的重建误差，包括被遮挡区域，验证了其超越传统立体视觉方法的完整3D占用推断能力。|Stefan Wermter Team|[2602.10943](http://arxiv.org/abs/2602.10943)|null|
|**2026-02-11**|**MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation**|通用人形机器人运动追踪器在仿真中性能优异，但在真实硬件上的持续遥操作中常因界面和动力学误差而脆弱。本文提出了MOSAIC，一个开源、全栈系统，用于跨多个界面的人形机器人运动追踪和全身遥操作。MOSAIC首先通过强化学习和自适应重采样，从多源运动库学习面向遥操作的通用运动追踪器，并强调世界坐标系下的运动一致性奖励。为弥合仿真到真实界面的差距，系统采用快速残差适应方法，通过训练特定界面策略并将其蒸馏到通用追踪器中的加性残差模块，优于传统的微调或持续学习。实验验证了MOSAIC在实际延迟和噪声下，具有鲁棒的离线运动重放和在线长时程遥操作能力。|Alois Knoll Team|[2602.08594](http://arxiv.org/abs/2602.08594)|null|
|**2026-02-10**|**EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration**|人类示范数据因其多样性和可扩展性在机器人领域极具吸引力，但其在数据需求更高的类人机器人运动操作问题上尚未得到充分探索。本文提出了EgoHumanoid框架，首次利用大量自我中心人类示范数据和少量机器人数据共同训练视觉-语言-动作策略，使人形机器人能在多样化真实环境中执行运动操作。为弥合人机形态与视角差异，框架引入了从硬件设计到数据处理的系统对齐管线，包括视图对齐和动作对齐。真实世界实验表明，引入无机器人自我中心数据使性能相比纯机器人基线提升了51%，尤其在未见环境中表现更优，并揭示了数据迁移潜力和规模化效应。|Li Chen Team|[2602.10106](http://arxiv.org/abs/2602.10106)|**[link](https://opendrivelab.com/EgoHumanoid)**|
|**2026-02-10**|**Humanoid Factors: Design Principles for AI Humanoids in Human Worlds**|随着人形机器人融入人类环境，设计挑战已扩展到需同时考虑人类和人形机器人的因素。本文引入了“人形机器人因素”概念，这是一个围绕物理、认知、社会和伦理四个支柱构建的框架，旨在指导人形机器人的发展，以实现与人类的有效共存与协作。该框架表征了人类能力与基于AI基础模型的通用人形机器人能力之间的异同。通过将该框架应用于评估一个真实世界的人形机器人控制算法，文章展示了传统机器人任务完成指标如何忽视关键的人类认知和交互原则，从而将“人形机器人因素”定位为设计、评估和管理可持续人机共存的基础框架。|Lixiao Huang Team|[2602.10069](http://arxiv.org/abs/2602.10069)|null|
|**2026-02-10**|**TeleGate: Whole-Body Humanoid Teleoperation via Gated Expert Selection with Motion Prior**|实时全身遥操作对人形机器人执行复杂任务至关重要，但现有统一控制器在支持多样化人类运动时常因知识蒸馏而导致性能下降。本文提出TeleGate，一个用于人形机器人的统一全身遥操作框架，通过训练轻量级门控网络，根据本体感受状态和参考轨迹动态激活领域专家策略，从而避免性能损失。为应对实时遥操作中未来轨迹缺失问题，引入VAE-based运动先验模块，从历史观测中提取未来运动意图以实现预期控制。在仿真和Unitree G1机器人上的实验表明，TeleGate仅用2.5小时运动捕捉数据便实现了高精度实时遥操作，在多种动态运动中显著优于基线方法。|Rongyun Cao Team|[2602.09628](http://arxiv.org/abs/2602.09628)|null|
|**2026-02-09**|**Characteristics, Management, and Utilization of Muscles in Musculoskeletal Humanoids: Empirical Study on Kengoro and Musashi**|针对现有类肌肉骨骼仿人机器人缺乏对其固有特性统一讨论的问题，本研究基于Kengoro和Musashi等已开发机器人，将类肌肉骨骼结构特性归纳为冗余性、独立性、各向异性、可变力臂和非线性弹性五类。研究分析了这些特性组合带来的优缺点，并探讨了通过身体图式学习、反射控制、肌肉分组及身体图式适应等方法管理和利用这些特性的方式。文章进一步描述了通过集成系统实现运动，并展望了未来的研究挑战与前景。|Masayuki Inaba Team|[2602.08518](http://arxiv.org/abs/2602.08518)|null|
|**2026-02-09**|**Learning Human-Like Badminton Skills for Humanoid Robots**|针对仿人机器人在羽毛球等高强度运动中难以实现多功能、类人表现的问题，本研究提出了“模仿到互动”的渐进式强化学习框架。该框架首先从人类数据构建运动先验，提炼为紧凑状态表示并利用对抗性先验稳定动力学，并通过流形扩展策略解决专家演示稀疏性。实验结果表明，该框架在模拟中掌握了多种技能，并首次实现了拟人化羽毛球技能从模拟到真实仿人机器人的零样本迁移，成功复现了人类运动员的动能优雅和功能精度。|Peng Lu Team|[2602.08370](http://arxiv.org/abs/2602.08370)|null|
|**2026-02-07**|**VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots**|现有仿人机器人面部表情模仿系统在实时性和真实表现力上存在局限。为解决此问题，本研究提出了VividFace系统，一个实时且逼真的仿人机器人面部表情跟随系统。该系统通过优化X2CNet++框架增强面部动作迁移表现力，并引入特征适应训练策略，同时利用视频流兼容推理管道和异步I/O实现实时性能。VividFace系统能在0.05秒内生动模仿人类面部表情，并泛化至多种面部配置，其在真实世界中的实用性已得到广泛验证。|Yang Zhang Team|[2602.07506](http://arxiv.org/abs/2602.07506)|null|
|**2026-02-07**|**TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control**|现有仿人机器人全身运动控制器在灵活性和自主性方面受限，难以实现实时交互。为此，本研究提出了TextOp，一个实时文本驱动的仿人机器人运动生成与控制框架。该框架采用两级架构，高层运动扩散模型生成短时域轨迹，低层跟踪策略在机器人上执行。TextOp通过连接交互式运动生成与鲁棒全身控制，实现了自由形式的意图表达和多种复杂行为（如舞蹈、跳跃）的平滑过渡，并通过真实机器人实验验证了其即时响应性、平滑运动和精确控制。|Xuelong Li Team|[2602.07439](http://arxiv.org/abs/2602.07439)|**[link](https://text-op.github.io/)**|
|**2026-02-07**|**Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots**|为解决大多数仿人机器人缺乏情感丰富的多模态表达且难以在设备端自主运行的问题，本研究提出了SeM $^2$ 框架。该框架基于视觉语言模型，通过多模态感知捕获用户情境，利用思维链推理规划响应，并引入语义序列对齐机制确保言语与肢体表达的时间协调。框架实现了云端和边缘部署版本，后者通过知识蒸馏高效运行。实验证明，该方法在自然性、情感清晰度和模态一致性方面显著优于单模态基线，推动了社交表达仿人机器人技术发展。|Miao Li Team|[2602.07434](http://arxiv.org/abs/2602.07434)|null|
|**2026-02-06**|**Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation**|针对机器人策略在部署后遇到的故障难以通过传统方式恢复的问题，本研究引入了一种受小脑启发的推理时残差控制框架。该框架通过在线校正动作增强已冻结的强化学习策略，无需修改基础参数即可实现故障恢复，其核心在于高维模式分离、并行残差路径以及局部误差驱动的可塑性。实验在MuJoCo基准测试中，显示在中度故障下，该框架使HalfCheetah-v5和Humanoid-v5的性能分别提升高达66%和53%，并展现了在严重偏移下的优雅性能下降以及互补的鲁棒性。|Amit Ranjan Trivedi Team|[2602.07227](http://arxiv.org/abs/2602.07227)|null|
|**2026-02-06**|**DynaRetarget: Dynamically-Feasible Retargeting using Sampling-Based Trajectory Optimization**|为解决人类动作向仿人机器人控制策略重定向中动态可行性问题，本研究提出了DynaRetarget，一个完整的重定向流程。其核心是新型基于采样的轨迹优化（SBTO）框架，能够将不完美的运动学轨迹细化为动态可行的运动，并通过逐步推进优化范围实现对长时域任务的整个轨迹优化。DynaRetarget成功重定向了数百个人-物体演示，取得了比现有技术更高的成功率，并能泛化至不同物体属性，有望解决真实世界数据收集瓶颈，促进大规模合成数据集的生成。|Majid Khadiv Team|[2602.06827](http://arxiv.org/abs/2602.06827)|null|
|**2026-02-06**|**ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking**|为解决仿人机器人节能稳定运动中现有方法需大量超参数调优且易导致次优策略的问题，本研究提出了ECO（Energy-Constrained Optimization）约束强化学习框架。该框架将能量指标明确定义为不等式约束，通过拉格朗日法强制执行能量消耗和参考运动约束，从而实现稳定、对称且节能的行走。ECO在仿真和真实机器人（BRUCE）上的实验结果表明，在保持鲁棒行走性能的同时，其能耗显著低于MPC、标准RL及其他SOTA约束RL方法，实现了仿人机器人节能运动的实质性进步。|Yao Su Team|[2602.06445](http://arxiv.org/abs/2602.06445)|null|
|**2026-02-06**|**Now You See That: Learning End-to-End Humanoid Locomotion from Raw Pixels**|为解决基于视觉的仿人机器人鲁棒运动中模拟到真实差距产生的感知噪声和多样地形下学习目标冲突的挑战，本研究提出了一个端到端的视觉驱动运动框架。为实现鲁棒的sim-to-real迁移，该框架开发了高保真深度传感器模拟，并提出了视觉感知行为蒸馏方法。为适应多样地形，引入了地形特定奖励塑形，并结合多评论家和多判别器学习。在配备不同立体深度摄像头的两个仿人机器人平台上，该策略展现出在多样环境中的鲁棒性能，能处理极端挑战和精细任务，包括双向长期楼梯遍历。|Zongwu Xie Team|[2602.06382](http://arxiv.org/abs/2602.06382)|null|

<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>
